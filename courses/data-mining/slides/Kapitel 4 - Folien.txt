DATA MINING

Kapitel 4: Empfehlungssysteme
Dr. Christian Martin
Wintersemester 2025/26

Abteilung Datenbanken / ScaDS.AI
UniversitÃ¤t Leipzig

THEMENÃœBERSICHT

Hochdimensionale Daten

Graphdaten

DatenstrÃ¶me

Clustering

Dimensionsreduktion

Community
Detection

Windowing

Empfehlungssysteme

Assoziationsregeln

PageRank

Filtern

Locality Sensitive
Hashing

Supervised ML

Web Spam

Momente

Data Mining | WiSe 2025/2026

4-2

INHALTSVERZEICHNIS
âˆ’ EinfÃ¼hrung
âˆ’ Inhaltsbasierte Analyse
âˆ’ Kollaboratives Filtern
âˆ’ Latentes Variablenmodell

Data Mining | WiSe 2025/2026

4-3

EMPFEHLUNGEN

Beispiele:

Suche

Empfehlungen

Produkte, Webseiten,
Blogs, Nachrichten,
Filme, Musik, Bilder, â€¦

Data Mining | WiSe 2025/2026

4-4

EMPFEHLUNGEN
âˆ’ UnzÃ¤hlige Informationen im WWW benÃ¶tigen Filter

âˆ’ Arten der Empfehlung
âˆ’ Redaktion: Liste der beliebtesten/wichtigsten Produkte
âˆ’ Globale Aggregate: Meist gekauften Produkte, Neuste Filme, â€¦
âˆ’ Benutzerdefiniert: Auf einzelnen User zugeschnitten

âˆ’ Nutzenmatrix
âˆ’ Menge von Usern
âˆ’ Menge von Objekten
âˆ’ Nutzenwerte in Zellen
âˆ’ Beispiel: 1-10 Sterne

Alice

Avatar LotR

Matrix Pirates

10

2

Bob
Carol

5
1

David

Data Mining | WiSe 2025/2026

3
5

4
4-5

FRAGESTELLUNG
âˆ’ SchÃ¤tzung der unbekannten Bewertungen
âˆ’ HauptsÃ¤chlich mÃ¶chte man die hohen Bewertungen wissen
âˆ’ Weniger interessant, welche Objekte nicht gemocht werden

âˆ’ Drei Herangehensweisen (u.a.):
âˆ’ Inhaltsbasierte Analyse
âˆ’ Kollaboratives Filtern
âˆ’ Latentes
Variablenmodell

Alice

Avatar LotR

Matrix Pirates

10

2

Bob

Carol

5

1

David
Data Mining | WiSe 2025/2026

3

5
4
4-6

AUCH GRAPH-BASIERT
âˆ’ Graph-ReprÃ¤sentation sehr geeignet fÃ¼r
Empfehlungssysteme
âˆ’ Nicht Bestandteil der VL
Person

Person

name : Chris

name : Kevin

follows

hasSeen

hasSeen

recommend
recommend

Movie

Movie

Movie

title : Inception
year : 2010

title : Mad Max
year : 2015

hasSeen

title : The Dark Knight Rises
year : 2012

directorOf

actedIn

directorOf

actedIn

actedIn

Actor

Director

name : Tom Hardy

name : Christopher Nolan

Data Mining | WiSe 2025/2026

4-7

INHALTSVERZEICHNIS
âˆ’ EinfÃ¼hrung
âˆ’ Inhaltsbasierte Analyse
âˆ’ Kollaboratives Filtern
âˆ’ Latentes Variablenmodell

Data Mining | WiSe 2025/2026

4-8

INHALTSBASIERTE ANALYSE
âˆ’ Idee: Empfehlung von Objekten fÃ¼r einen Nutzer, wenn Ã¤hnliche
Objekte von dem Nutzer bereits positiv bewertet wurden
âˆ’ Beispiele:
âˆ’ Empfehle Filme mit gleichen Schauspielern, Regisseur, Genre, â€¦
âˆ’ Empfehle Webseiten mit Ã¤hnlichen Themen/WÃ¶rtern

Hohe Bewertung

Objektprofil
Empfehlung
Zuordnung

Rot
Kreise
Dreiecke

Data Mining | WiSe 2025/2026

Nutzerprofil
4-9

INHALTSBASIERTE ANALYSE
âˆ’ Objektprofil: Menge von Merkmalen
âˆ’ z.B. Filme mit Schauspielern,
Regisseur, Genre, â€¦
Cameron

Wachowski

UK

Action

Fantasy

Avatar 1

0

1

1

1

Matrix

1

1

1

0

0

Nutzenmatrix
Avatar Matrix
Alice

10

2

Carol

1

5

Zentrierung
(pro Nutzer)
Avatar Matrix

âˆ’ Nutzerprofil:

Alice

4

-4

Carol

-2

2

âˆ’ Gewichtung der Objektprofile mit zentrierter Bewertung
4 âˆ— 1 + âˆ’4 âˆ— 0

Cameron

Wachowski

UK

Action

Fantasy

Alice

4

-4

0

0

4

Carol

-2

2

0

0

-2

Data Mining | WiSe 2025/2026

4-10

KOSINUS Ã„HNLICHKEIT

cos ğ’™, ğ² =

ğ’™Â·ğ’š
ğ’™ â‹… ğ’š

âˆˆ [âˆ’1,1] mit ğ‘¥ =

Ïƒğ‘– ğ‘¥ğ‘–2 und ğ‘¦ =

Ïƒğ‘– ğ‘¦ğ‘–2

Quelle: https://www.learndatasci.com/glossary/cosine-similarity/
https://de.wikipedia.org/wiki/Sinus_und_Kosinus#/media/Datei:Sine_cosine_one_period.svg

Data Mining | WiSe 2025/2026

4-11

INHALTSBASIERTE ANALYSE
âˆ’ Unbewerteter Film
Titanic

Cameron

Wachowski

UK

Action

Fantasy

1

0

1

0

0

âˆ’ Ã„hnlichkeit zwischen Objekt und Nutzer
âˆ’ z.B. Ã¼ber Kosinus-Ã„hnlichkeit

cos ğ’™, ğ² =

ğ’™Â·ğ’š
ğ’™ â‹… ğ’š

âˆˆ [âˆ’1,1]

Cameron

Wachowski

UK

Action

Fantasy

Alice

4

-4

0

0

4

Carol

-2

2

0

0

-2

âˆ’ Beispiel
âˆ’ Alice: cos ğ’™, ğ² =
âˆ’ Carol: cos ğ’™, ğ² =

4âˆ—1
12 +12 âˆ— 4 2 +âˆ’4 2 +4
âˆ’2âˆ—1

4

= 9.8 = 0.41
2
âˆ’2

= 4.9 = âˆ’0.41
2

12 +12 âˆ— âˆ’22 +22 +âˆ’2

Data Mining | WiSe 2025/2026

4-12

INHALTSBASIERTE ANALYSE: PROBLEME
âˆ’ Alle Interessen eines Users mÃ¼ssen mit Objektprofil
Ã¼bereinstimmen
âˆ’ Leidenschaft fÃ¼r Feature "Cameron" ist nicht trennbar von
Interesse fÃ¼r "Fantasy"
âˆ’ Durchaus vorstellbar, dass beide Bewertungen aus
unterschiedlichen Filmen stammen und Alice alles von Cameron
mag (unabhÃ¤ngig des Genre)
âˆ’ â†’ komplexere ZusammenhÃ¤nge nicht abbildbar

âˆ’ Merkmale mÃ¼ssen von Hand gewÃ¤hlt werden
âˆ’ evtl. wurden aber nicht alle relevanten Merkmale identifiziert, z.B.
kÃ¶nnte auch Ort des Filmes wichtig sein.

Data Mining | WiSe 2025/2026

4-13

INHALTSVERZEICHNIS
âˆ’ EinfÃ¼hrung
âˆ’ Inhaltsbasierte Analyse
âˆ’ Kollaboratives Filtern
âˆ’ Latentes Variablenmodell

Data Mining | WiSe 2025/2026

4-14

KOLLABORATIVES FILTERN
âˆ’ Kollaboratives Filtern (KF) fÃ¼r Nutzer
âˆ’ Auswertung von Verhaltensmuster von Benutzergruppen
âˆ’ Suche nach einer Menge ğ‘ von Nutzern mit Ã¤hnlichen PrÃ¤ferenzen
(Nutzenmatrix)
âˆ’ SchÃ¤tzung der unbekannten Bewertungen Ã¼ber die Bewertungen der
Nutzer aus ğ‘

âˆ’ Alternative: KF fÃ¼r Objekte
âˆ’ Suche nach einer Menge ğ‘ von Objekten mit Ã¤hnlichen Bewertungen
âˆ’ SchÃ¤tzen der unbekannten Bewertungen Ã¼ber die Bewertungen der
Objekte aus ğ‘
âˆ’ Vorteil: Objekte sind oft einfacher klassifizierbar als Menschen
âˆ’ Ein Musikalbum ist entweder Death Metal oder Klassik
âˆ’ Menschen kÃ¶nnen beide Musikrichtungen mÃ¶gen
âˆ’ MÃ¶glich, das zwei Menschen Death Metal mÃ¶gen und gleichzeitig
eine andere Musikrichtung, fÃ¼r die sich der jeweils andere gar nicht
begeistert
Data Mining | WiSe 2025/2026

4-15

KOLLABORATIVES FILTERN FÃœR OBJEKTE
âˆ’ Sei ğ‘Ÿğ‘¥ğ‘– die Bewertung des Nutzers ğ‘¥ zu Objekt ğ‘–
âˆ’ Keine Bewertung ğ‘Ÿğ‘¥ğ‘– fÃ¼r Objekt ğ‘– â†’ soll geschÃ¤tzt werden
âˆ’ Sei ğ‘µ(ğ’Š; ğ’™) die Menge der ğ‘˜ Ã¤hnlichsten Objekte, welche
von x bewertet wurden
âˆ’ SchÃ¤tzung 1 (aus ğ‘˜ Ã¤hnlichsten Objekten):
1
âˆ’ Mittelwert: ğ‘Ÿğ‘¥ğ‘–
Æ¸ = Ïƒjâˆˆğ‘µ(ğ’Š;ğ’™) ğ‘Ÿxj
ğ‘˜

âˆ’ SchÃ¤tzung 2 (+ Gewichtung nach Ã„hnlichkeit):
âˆ’ ğ‘Ÿğ‘¥ğ‘–
Æ¸ =

Ïƒjâˆˆğ‘(i;x) ğ‘ ğ‘–ğ‘— â‹…ğ‘Ÿğ‘¥ğ‘—
Ïƒjâˆˆğ‘(i;x) ğ‘ ğ‘–ğ‘—

ğ‘ ğ‘–ğ‘— =(Kosinus-)Ã„hnlichkeit zwischen
Objekt ğ‘– und ğ‘—

Data Mining | WiSe 2025/2026

4-16

KOLLABORATIVES FILTERN FÃœR OBJEKTE

âˆ’ Sei ğ‘Ÿğ‘¥ğ‘– die Bewertung des Nutzers ğ‘¥ zu Objekt ğ‘–
âˆ’ ğ’“.ğ‘– : Bewertung aller Nutzer zu Objekt ğ‘–
âˆ’ Sei ğ‘ ğ‘–ğ‘— (Kosinus-)Ã„hnlichkeit zwischen Objekt ğ‘– und ğ‘—
ğ‘ ğ‘–ğ‘— =

ğ«.ğ‘– Â·ğ«.ğ‘—
ğ«.ğ‘– â‹… ğ«.ğ‘—

=

Ïƒğ‘¥ ğ‘Ÿğ‘¥ğ‘– Â·ğ‘Ÿğ‘¥ğ‘—
2
Ïƒğ‘¥ ğ‘Ÿğ‘¥ğ‘–

2
Ïƒğ‘¥ ğ‘Ÿğ‘¥ğ‘—

âˆˆ âˆ’1,1

âˆ’ Sind Bewertungen zentriert entspricht ğ‘ ğ‘–ğ‘— dem PearsonKorrelationskoeffizient

Data Mining | WiSe 2025/2026

4-17

KOLLABORATIVES FILTERN FÃœR OBJEKTE
Nutzer
1
1

2

1

Filme

5
2

4

6

4
2

5

5

6

?

5

4
1

4
4

1

4

3

2
3

3

3

2

4

3

Unbekannt

8

9

10 11 12

5

4

4
3

5
3

7

4
4

2

2

1

3

5
2
2

2

3

5

4

Bewertung

Data Mining | WiSe 2025/2026

4-18

ZENTRIERUNG

Zeile 1
m1 = (1+3+5+5+4)/5 = 3.6
-> 1-3.6, 3-3.6, ..

zeilenweise Zentrierung

Nutzer
1
1

2

-2.6

Filme

1.8

-1

4

6

1
-1.4

5

5

0.8

7

8

0.8

0.7
0.4

10

0.6

-1.3

11

-2.2

Data Mining | WiSe 2025/2026

-0.2

2
-1.4

-1.3
-0.6

12

0.4
-1.2

1

1.6

-0.3

9
1.4

-1

0.6

0.4

6
1.4

-2

0.7
-1.6

4

-0.6

2

3

3

1.7

1.4

4-19

BERECHNUNG DER Ã„HNLICHKEITEN VON OBJEKTEN
Nutzer
1
1

2

-2.6

Filme

1.8
-1

4

6

1
-1.4

5

5

0.8

0.6

0.4

6

7

8

1.4

-2

0.7
-1.6

4

-0.6

2
3

3

1

0.4

0.6

-1.3

11

-2.2

ğ’”ğŸğ’‹

1.00
-0.2

2

-0.18

0.41

-1.4

-1.3
-0.6

12

0.4
-1.2

-1

0.7

10

1.4
0.8

1.6

-0.3

9

-0.10
1.7

-0.31

1.4

0.59
Ã„hnlichkeit zwischen Film 1 und Film 2:
âˆ’0.6 âˆ— 1.8 + 0.4 âˆ— âˆ’2.2
âˆ’1.96
ğ‘ 12 =
=
11.2 âˆ— 10.84
âˆ’2.62 + âˆ’0.62 + 1.42 + 1.42 + 0.42 âˆ— 1.82 + 2 âˆ— 0.82 + âˆ’1.22 + âˆ’2.22 + âˆ’0.22
â‰ˆ âˆ’0.18
Data Mining | WiSe 2025/2026

4-20

KOLLABORATIVES FILTERN FÃœR OBJEKTE
Nutzer

k=2

1
1

2

1

Filme

5
2

4

6

4
2

5

5

6

??

5

4
1

4
4

1

4

3

2
3

3

3

2

4
3

Unbekannt

8

9

10 11 12

ğ’”ğŸğ’‹

5

4

1.00

4
3

5
3

7

4
4

2

2

1

3

5

0.41

2

-0.10

2
2

4

3

5

-0.18

-0.31
0.59

Bewertung

Data Mining | WiSe 2025/2026

4-21

KOLLABORATIVES FILTERN FÃœR OBJEKTE
Nutzer

k=2

1
1

2

1

Filme

5
2

4

6

4
2

5

6

4

4

3

5

7

8

2.6 5

1

4
1

4

3

2
3

3

10 11 12

ğ’”ğŸğ’‹

5

4

1.00

4
2

3

5
3

9

4
3

4
4

2

1

3

5

0.41

2

-0.10

2
2

4

3

-0.18

2

5

-0.31
0.59

Ïƒğ‘—âˆˆğ‘(ğ‘–;ğ‘¥) ğ‘ ğ‘–ğ‘— â‹… ğ‘Ÿğ‘—ğ‘¥ 0.41 âˆ™ 2 + 0.59 âˆ™ 3
ğ‘Ÿğ‘–ğ‘¥
Æ¸ =
=
= 2.6
Ïƒğ‘—âˆˆğ‘(ğ‘–;ğ‘¥) ğ‘ ğ‘–ğ‘—
0.41 + 0.59
Data Mining | WiSe 2025/2026

4-22

VERGLEICH: VORTEILE
Kollaboratives Filtern

Inhaltsbasierte Analyse

Keine Auswahl von Merkmalen
notwendig (insb. bei Bildern)

BenÃ¶tigt keine Daten anderer Nutzer

Trennung verschiedener
Interessen eines Nutzers
mÃ¶glich (KF fÃ¼r Objekte)

Empfehlungen fÃ¼r Nutzer mit einzigartigem
Geschmack mÃ¶glich
Empfehlungen von neuen/unpopulÃ¤ren
Objekten mÃ¶glich
ErklÃ¤rung fÃ¼r Empfehlung mÃ¶glich: Auflisten
der Merkmale mit hÃ¶chstem Gewicht

â€“
â€“

Allgemeines Problem: Nutzenmatrix ist oft spÃ¤rlich besetzt
LÃ¶sung (siehe auch Ãœbungsaufgabe):
â€“ Clusteranalyse auf Objekte und Zusammenfassen der Objekte eines
Clusters (Mittelwert Ã¼ber Bewertungen)
â€“ AnschlieÃŸend Clusteranalyse auf Nutzer und Zusammenfassen der
Nutzer eines Clusters (Mittelwert Ã¼ber gemittelte Bewertungen)
â€“ Wiederholung des Prozesses bis Matrix ausreichend besetzt
Data Mining | WiSe 2025/2026

4-23

NETFLIX PRIZE
âˆ’ Trainingsdaten
âˆ’ 100 Million Bewertungen (1-5 Sterne)
âˆ’ ca. 480 000 zufÃ¤llig ausgewÃ¤hlte Nutzer
âˆ’ ca. 17 770 Filme
âˆ’ Zeitraum: 2000-2005

âˆ’ Testdaten
âˆ’ Menge ğ‘…: die letzten Bewertungen der ausgewÃ¤hlten Nutzer (2.8M)
âˆ’ Evaluation Ã¼ber Root Mean Squared Error (RMSE):
âˆ’

1
2
Ïƒ(ğ‘–,ğ‘¥)âˆˆğ‘… ğ‘Ÿğ‘¥ğ‘–
Æ¸
âˆ’
ğ‘Ÿ
ğ‘¥ğ‘–
ğ‘…

âˆ’ System von Netflix: CineMatch
âˆ’ RMSE von CineMatch: 0.9514 (durchschnittlicher Fehler: ein Stern)

âˆ’ Wettbewerb: $1 Million fÃ¼r das erste Team, dessen Algorithmus eine
Verbesserung um 10% (RMSE von 0.8572 oder weniger) erreicht
Data Mining | WiSe 2025/2026

4-24

NETFLIX PRIZE: RMSE
Globaler Durchschnitt: 1.13
Nutzerdurchschnitt: 1.07
Filmdurchschnitt: 1.05

CineMatch: 0.95

Kollaboratives Filtern: 0.94

Grand Prize: 0.8563

Data Mining | WiSe 2025/2026

4-25

KOLLOBORATIVES FILTERN MIT BIAS
âˆ’ KF fÃ¼r Objekte:

ğ‘Ÿğ‘¥ğ‘–
Æ¸ =

Ïƒğ‘—âˆˆğ‘(ğ‘–;ğ‘¥) ğ‘ ğ‘–ğ‘— â‹… ğ‘Ÿğ‘¥ğ‘—

Ïƒğ‘—âˆˆğ‘(ğ‘–;ğ‘¥) ğ‘ ğ‘–ğ‘—

âˆ’ Bessere Ergebnisse durch BerÃ¼cksichtigung â€globaler Effekteâ€œ:
âˆ’ Globaler Durchschnitt aller Bewertungen ğ
ğŸ

âˆ’ Nutzerbias: ğ’ƒğ’™âˆ— = ğ’ Ïƒğ’Š ğ’“ğ’™ğ’Š âˆ’ ğ (ğ‘›ğ‘¥ ist Anzahl der Bewertungen von x)
ğ’™

ğŸ

âˆ’ Filmbias: ğ’ƒâˆ—ğ’Š = ğ’ Ïƒğ’™ ğ’“ğ’™ğ’Š âˆ’ ğ (ğ‘›ğ‘– ist Anzahl der Bewertungen fÃ¼r i)
ğ’Š

âˆ’ Baseline-SchÃ¤tzer fÃ¼r ğ‘Ÿğ’™ğ’Š
Æ¸ : ğ’ƒğ’™ğ’Š = ğ + ğ’ƒğ’™âˆ— + ğ’ƒâˆ—ğ’Š

âˆ’ KF mit Bias (systematische Verschiebung):
Ïƒğ‘—âˆˆğ‘(ğ‘–;ğ‘¥) ğ‘ ğ‘–ğ‘— âˆ™ (ğ‘Ÿğ‘¥ğ‘— âˆ’ ğ‘ğ‘¥ğ‘— )
ğ‘Ÿğ‘¥ğ‘–
Æ¸ â‰… ğ‘ğ‘¥ğ‘– +
Ïƒğ‘—âˆˆğ‘(ğ‘–;ğ‘¥) ğ‘ ğ‘–ğ‘—

Data Mining | WiSe 2025/2026

4-26

KOLLOBORATIVES FILTERN MIT BIAS
âˆ’ Am Beispiel
âˆ’ Globaler Durchschnitt aller Bewertungen ğ
âˆ’ ğ = 3.17
ğŸ

âˆ’ Nutzerbias: ğ’ƒğ’™âˆ— = ğ’ Ïƒğ’Š ğ’“ğ’™ğ’Š âˆ’ ğ (ğ‘›ğ‘¥ ist Anzahl der Bewertungen von x)
ğ’™

âˆ’ ğ’ƒ5âˆ— = 0.33
ğŸ

âˆ’ Filmbias: ğ’ƒâˆ—ğ’Š = ğ’ Ïƒğ’™ ğ’“ğ’™ğ’Š âˆ’ ğ (ğ‘›ğ‘– ist Anzahl der Bewertungen fÃ¼r i)
ğ’Š

âˆ’ ğ’ƒâˆ—1 = 0.43

âˆ’ Baseline-SchÃ¤tzer fÃ¼r ğ‘Ÿğ’™ğ’Š
Æ¸ : ğ’ƒğ’™ğ’Š = ğ + ğ’ƒğ’™âˆ— + ğ’ƒâˆ—ğ’Š
âˆ’ ğ’ƒ51 = ğ + ğ’ƒ5âˆ— + ğ’ƒâˆ—1 = 3.17 + 0.33 + 0.43 = ğŸ‘. ğŸ—ğŸ‘
âˆ’ ğ’ƒ53 = ğ + ğ’ƒ5âˆ— + ğ’ƒâˆ—3 = 3.17 + 0.33 âˆ’ 0.17 = 3.33
âˆ’ ğ’ƒ56 = ğ + ğ’ƒ5âˆ— + ğ’ƒâˆ—6 = 3.17 + 0.33 âˆ’ 0.57 = 2.93

ğ‘Ÿ51
Æ¸ = 3.93 +

0.41 âˆ™ 2 âˆ’ 3,33 + 0.59 âˆ™ 3 âˆ’ 2.93
âˆ’0.504
= 3.93 +
= ğŸ‘. ğŸ’ğŸğŸ”
0.41 + 0.59
1
Data Mining | WiSe 2025/2026

4-27

KF MIT BIAS UND GELERNTEN GEWICHTEN
âˆ’ Problem bei Verwendung von ğ‘ ğ‘–ğ‘— : willkÃ¼rlich festgelegtes
MaÃŸ (z.B. Kosinus-Ã„hnlichkeit)
âˆ’ Anpassung Ã¼ber gewichtete Summe Ã¼ber k Ã¤hnlichste
Objekte:
âˆ’ ğ‘Ÿğ‘¥ğ‘–
Æ¸ = ğ‘ğ‘¥ğ‘– + Ïƒğ‘˜ ğ‘¤ğ‘–ğ‘˜ ğ‘Ÿğ‘¥ğ‘˜ âˆ’ ğ‘ğ‘¥ğ‘˜
âˆ’ Die Gewichte ğ’˜ğ’Šğ’Œ (fÃ¼r Nutzer ğ‘– und Film ğ‘˜) werden
gelernt: Minimierung des RMSE bei Anwendung auf
Trainingsdaten
âˆ’ Problem 1: Overfitting â€“ optimale LÃ¶sung auf Trainigsdaten nicht
unbedingt allgemein gute LÃ¶sung (â†’ Cross-Validation)
âˆ’ Problem 2: Lernen der Gewichte
Data Mining | WiSe 2025/2026

4-28

KF MIT BIAS UND GELERNTEN GEWICHTEN
âˆ’ Finde Gewichte ğ’˜ = (ğ‘¤ğ‘–ğ‘— ), die folgenden Ausdruck
Berechneter Wert
minimieren:
realer Wert

âˆ’ ğ½ ğ‘¤ = Ïƒğ‘¥,ğ‘– ğ‘Ÿğ‘¥ğ‘–
Æ¸ âˆ’ ğ‘Ÿğ‘¥ğ‘– 2
âˆ’

= Ïƒğ‘¥,ğ‘– ğ‘ğ‘¥ğ‘– + Ïƒğ‘˜ ğ‘¤ğ‘–ğ‘˜ ğ‘Ÿğ‘¥ğ‘˜ âˆ’ ğ‘ğ‘¥ğ‘˜

âˆ’ ğ‘Ÿğ‘¥ğ‘– 2

âˆ’ Gradient Descent: Einfacher Algorithmus um
lokales Minimum zu finden
âˆ’ Wiederhole bis Konvergenz:
ğ’˜ â† ğ’˜ âˆ’ ï¨ğ›»ğ‘¤ ğ½
âˆ’ Lernrate: ï¨
âˆ’ Gradient an der Stelle (i,j):
âˆ’ (ğ›»ğ‘¤ ğ½)ij =

ğœ•ğ½(ğ‘¤)
= 2 Ïƒğ‘¥
ğœ•ğ‘¤ğ‘–ğ‘—

ğ‘ğ‘¥ğ‘– + Ïƒğ‘˜ ğ‘¤ğ‘–ğ‘˜ ğ‘Ÿğ‘¥ğ‘˜ âˆ’ ğ‘ğ‘¥ğ‘˜

Data Mining | WiSe 2025/2026

âˆ’ ğ‘Ÿğ‘¥ğ‘– ğ‘Ÿğ‘¥ğ‘— âˆ’ ğ‘ğ‘¥ğ‘—
4-29

STOCHASTIC GRADIENT DESCENT

Minimierungsfunktion

âˆ’ Gradienten fÃ¼r die Elemente der Gewichtungsmatrix sind Summen
Ã¼ber mehrere Datenpunkte: Berechnung kann sehr lange dauern
âˆ’ Schnellere Konvergenz wenn, fÃ¼r jede Iteration, nur ein (zufÃ¤llig
ausgewÃ¤hlter) Mini-Batch der Daten verwendet wird
âˆ’ SGD : stochastische Approximation von GD

â€” Gradient Descent
â€” Stochastic Gradient Descent

Iteration
Data Mining | WiSe 2025/2026

4-30

NETFLIX PRIZE: RMSE
Globaler Durchschnitt: 1.13
Nutzerdurchschnitt: 1.07
Filmdurchschnitt: 1.05

CineMatch: 0.95

Kollaboratives Filtern: 0.94
KF + Bias + gelernte Gewichte: 0.91

Grand Prize: 0.8563

Data Mining | WiSe 2025/2026

4-31

INHALTSVERZEICHNIS
âˆ’ EinfÃ¼hrung
âˆ’ Inhaltsbasierte Analyse
âˆ’ Kollaboratives Filtern
âˆ’ Latentes Variablenmodell

Data Mining | WiSe 2025/2026

4-32

LATENTES VARIABLENMODELL
âˆ’ Ein latentes Variablenmodell beschreibt den
Zusammenhang zwischen beobachtbaren (oder
manifesten) Variablen und dahinter liegenden
latenten(versteckten) Variablen
âˆ’ Im Beispiel:
âˆ’ beobachtete Variablen: Bewertungen der Nutzer fÃ¼r Filme
âˆ’ Latente/versteckte Variablen: Faktoren, die diese Bewertungen
beeinflussen, aber nicht direkt beobachtet werden kÃ¶nnen

Data Mining | WiSe 2025/2026

4-33

LATENTES VARIABLENMODELL
Ernst
The Color
Purple

The Dark Knight Rises

Titanic

Pride and
Prejudice

Die Hard

Twilight

Romantik

Shrek

Action

Independence Day

The Princess
Diaries

Dumb and
Dumber

SpaÃŸ
Data Mining | WiSe 2025/2026

4-34

LATENTES VARIABLENMODELL
âˆ’ Reduktion der Dimensionen auf wenige Faktoren
âˆ’ Zerlegung: ğ‘… â‰ˆ ğ‘„ Â· ğ‘ƒğ‘‡ fÃ¼r nicht-leere Zellen von R
Nutzer
3

5

5 4
2 4
2 4

5
4

1 2

4
2 1 3

3

5

4 3 5
4

2

4 3 4 2
1

3

3

â‰ˆ

2 5
2

4

R Faktoren
.1

-.4

.2

-.5

.6

.5

-.2

.3

.5

1.1

2.1

.3

-.7

2.1

-2

-1

.7

.3

Nutzer
x

1.1

-.2

.3

.5

-2

-.5

.8

-.4

.3

1.4

2.4

-.9

-.8

.7

.5

1.4

.3

-1

1.4

2.9

-.7

1.2

-.1

1.3

2.1

-.4

.6

1.7

2.4

.9

-.3

.4

.8

.7

-.6

.1

PT

Q
Data Mining | WiSe 2025/2026

4-35

Faktoren

Filme

Filme

1

LATENTES VARIABLENMODELL
âˆ’ SchÃ¤tzung der Werte der leeren Felder Ã¼ber Faktoren
Nutzer
3

5

5

5 4 ?

4

1 2

3

2 4
2 4

5

1

3

4
2 1 3

4 3 5
4

ğ’“à·œ ğ’™ğ’Š = à· ğ’’ğ’Šğ’‡ â‹… ğ’‘ğ’™ğ’‡

â‰ˆ

2

4 3 4 2

ğ’‡

2 5

3

2

4

R
Faktoren
.1

-.4

.2

-.5

.6

.5

-.2

.3

.5

1.1

-.2

.3

.5

-2

-.5

.8

-.4

.3

1.4

2.4

-.9

1.1

2.1

.3

-.8

.7

.5

1.4

.3

-1

1.4

2.9

-.7

1.2

-.1

1.3

-.7

2.1

-2

2.1

-.4

.6

1.7

2.4

.9

-.3

.4

.8

.7

-.6

.1

-1

.7

.3

Nutzer

Faktoren

Filme

Filme

1

PT

Q
Data Mining | WiSe 2025/2026

4-36

LATENTES VARIABLENMODELL
âˆ’ Ziel: Finden zweier Matrizen ğ‘„ und ğ‘ƒ, so dass folgender Ausdruck
fÃ¼r alle vorhandenen Felder minimiert wird
âˆ’ Ïƒğ’Š,ğ’™ ğ‘Ÿğ‘¥ğ‘– âˆ’ ğ‘ğ‘– â‹… ğ‘ğ‘¥ 2 (Kostenfunktion)
âˆ’ ğ‘Ÿğ‘¥ğ‘– : tatsÃ¤chliche Bewertung von Nutzer x fÃ¼r Film i
âˆ’ ğ‘ğ‘– bzw. ğ‘ğ‘¥ bezeichnet die i-te Zeile von Q bzw. x-te Zeile von P

âˆ’ ğ‘ğ‘– â‹… ğ‘ğ‘¥ : vorhergesagte Bewertung

âˆ’ Bestes Ergebnis fÃ¼r Trainingsdaten durch hohe Anzahl an Faktoren
(Spalten von Q und P) â†’ Gefahr: Overfitting
âˆ’ â€Auswendig lernenâ€œ der Daten (inkl. zufÃ¤lliger Fehler)
âˆ’ Keine Generalisierung auf unbekannte Daten mÃ¶glich â†’ Hohe
Fehlerrate bei Testdaten

âˆ’ LÃ¶sung: Regularisierung

Data Mining | WiSe 2025/2026

4-37

REGULARISIERUNG
âˆ’ Regularisierung fÃ¼gt Strafterme hinzu, die die KomplexitÃ¤t der
Matrizen Q und P begrenzen
âˆ’ min Ïƒğ’Š,ğ’™ ğ‘Ÿğ‘¥ğ‘– âˆ’ ğ‘ğ‘– â‹… px 2 + ğœ†1 Ïƒğ‘¥ ğ‘ğ‘¥ 2 + ğœ†2 Ïƒğ‘– ğ‘ğ‘– 2
ğ‘ƒ,ğ‘„

âˆ’ ğœ†1 Ïƒğ‘¥ ğ‘ğ‘¥ 2
âˆ’ Term bestraft groÃŸe Werte in den Zeilen von P (Nutzerfaktoren)
âˆ’ ğ‘ğ‘¥ 2 : quadratische Norm der Zeile ğ‘ğ‘¥
âˆ’ groÃŸer Wert = hohe Gewichtung der Nutzerfaktoren, was das Modell
anfÃ¤llig fÃ¼r Overfitting macht
âˆ’ Regularisierungsparameter ğœ†1 kontrolliert, wie stark Bestrafung

âˆ’ ğœ†2 Ïƒğ‘– ğ‘ğ‘– 2
âˆ’ Term bestraft groÃŸe Werte in den Zeilen von Q (Filmfaktoren)
âˆ’ Regularisierung zwingt das Modell, einfachere LÃ¶sungen zu finden, indem es die
Werte der latenten Faktoren Q und P begrenzt: generalisierbare Muster
âˆ’ Hohe Werte fÃ¼r ğœ†1 und ğœ†2 : stÃ¤rkere Bestrafung groÃŸer Werte in Q und P: Modell wird
dadurch einfacher, aber mÃ¶glicherweise unterangepasst
Data Mining | WiSe 2025/2026

4-38

EFFEKT DER REGULARISIERUNG
Ernst
The Color
Purple

The Dark Knight Rises

Titanic

Pride and
Prejudice

Die Hard

Twilight

Romantik

Shrek

Action

Independence Day

The Princess
Diaries

Dumb and
Dumber

SpaÃŸ
Data Mining | WiSe 2025/2026

4-39

BERECHNUNG
âˆ’ Ãœber (stochastic) Gradient Descent
âˆ’ Ziel: minimierung der Kostenfunktion und Optimierung
von ğ‘ƒ und ğ‘„
âˆ’ min Ïƒğ’Š,ğ’™ ğ‘Ÿğ‘¥ğ‘– âˆ’ ğ‘ğ‘– â‹… ğ‘ğ‘¥ 2 + ğœ†1 Ïƒğ‘¥ ğ‘ğ‘¥ 2 + ğœ†2 Ïƒğ‘– ğ‘ğ‘– 2
ğ‘ƒ,ğ‘„

âˆ’ Gradient Descent:
âˆ’ ğ‘ƒ âŸµ ğ‘ƒ âˆ’ ğœ‚ âˆ™ ğ›»ğ‘ƒ mit ğ›»P = [ğ›»pğ‘¥ğ‘“ ] und
âˆ’ ğ›»pxğ‘“ = Ïƒğ‘– âˆ’2 ğ‘Ÿğ‘¥ğ‘– âˆ’ ğ‘ğ‘– â‹… ğ‘ğ‘¥ qiğ‘“ + 2ğœ†1 ğ‘xğ‘“

âˆ’ ğ‘„ âŸµ ğ‘„ âˆ’ ğœ‚ âˆ™ ğ›»ğ‘„ mit ğ›»ğ‘„ = [ğ›»ğ‘iğ‘“ ] und
âˆ’ ğ›»ğ‘iğ‘“ = Ïƒğ‘¥ âˆ’2 ğ‘Ÿğ‘¥ğ‘– âˆ’ ğ‘ğ‘– â‹… ğ‘ğ‘¥ ğ‘ğ‘¥ğ‘“ + 2ğœ†2 ğ‘jğ‘“

âˆ’ ğ‘ƒ anpassen, ğ‘„ anpassen, Wiederholung bis Minimum
Data Mining | WiSe 2025/2026

4-40

NETFLIX PRIZE: BEWERTUNGEN
Globaler Durchschnitt: 1.13
Nutzerdurchschnitt: 1.07
Filmdurchschnitt: 1.05

CineMatch: 0.95

Kollaboratives Filtern: 0.94
KF + Bias + gelernte Gewichte: 0.91
Latente Variablen: 0.90
Latente Variablen + Bias: 0.89
Latent Variablen + Bias + Zeit: 0.876

ğ’“à·œ ğ’™ğ’Š = ğ’’ğ’Š â‹… ğ’‘ğ’™

ğ’“à·œ ğ’™ğ’Š = ğ + ğ’ƒğ’™ + ğ’ƒğ’Š + ğ’’ğ’Š â‹… ğ’‘ğ’™
ğ’“à·œ ğ’™ğ’Š = ğ + ğ’ƒğ’™ (ğ’•) + ğ’ƒğ’Š (ğ’•) + ğ’’ğ’Š â‹… ğ’‘ğ’™ (ğ’•)
Grand Prize: 0.8567

Data Mining | WiSe 2025/2026

4-41

Data Mining | WiSe 2025/2026

4-42

ZUSAMMENFASSUNG
âˆ’ Empfehlung Ã¼ber SchÃ¤tzung der unbekannten Bewertungen von
Nutzenmatrix
âˆ’ Inhaltsbasierte Analyse
âˆ’ Manuell festgelegte Merkmale
âˆ’ Ã„hnlichkeit zwischen Objekt und Nutzer

âˆ’ Kollaboratives Filtern
âˆ’ Verhaltensmuster von Benutzergruppen
âˆ’ SchÃ¤tzung aus Ã¤hnlichen Objekten + Gewicht + Bias
âˆ’ (S)GD um Gewichte zu finden (statt Ã„hnlichkeit)

âˆ’ Latentes Variablenmodell
âˆ’ Faktoren nutzen, die nicht direkt beobachtet werden kÃ¶nnen
âˆ’ Zerlegung ğ‘… â‰ˆ ğ‘„ Â· ğ‘ƒğ‘‡
âˆ’ (S)GD um Q und P zu bestimmen
âˆ’ Regularisierung um Overfitting zu vermeiden
Data Mining | WiSe 2025/2026

4-43

