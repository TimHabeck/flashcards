Teil einer Probeklausur (fuer 80-90 Minuten)
Alexander Binder
Some stuff

Disclaimer
This does not inform you about the expected difficulty level or the number
of tasks, or NLP tasks, or the number of vision tasks or the fraction of vision
to NLP tasks. It gives you merely an idea what type of questions to expect
for vision tasks. These are tasks for 80-90 minutes. The exam will be for 120
minutes.
• For calculations, always show your intermediate calculations!
• For other answers give a briefly explanation why (, ... unless you are
explicitly told not to).

Task1
Assume you want to predict the number of people in a country supporting that
the country is or becomes a member of the European Union. Denote this true
number y and the prediction ŷ. As inputs you have three values; the population
count x1 , the country’s land area x2 , and the gross domestic product (GDP)
per capita x3 . Make an illustration of a neural network depicting the following
relation between the inputs and the prediction:


3
2
X
X
f (x) =
wk g 
vjk xj + bk  + c
k=0

j=0

where wk , vjk , bk and c are trainable parameters and g is the logistic sigmoid
function.
• What is the output space for this network?
• What is the dimensionality of the trainable parameters?

1

• Without changing the number of trainable parameters, how would you
change the network so that it outputs a value between 0 and 1 indicating
the proportion of people (instead of the number of people) in a country
supporting that the country is or becomes a member of the European
Union?

Task2
Compute the directional derivative for
f (x) = x⊤ ABx + w · x + c
where x.shape= (5, 1), A.shape= (5, 7), B.shape= (7, 5), w.shape= (5, 1)

Task3
• What do dropout layers do in terms of computation?
• What is the reason for using dropout layers? Why one can expect them
to provide better predictions? The answer to this should be 2-5 sentences,
not one word.

Task4
• A two-dimensional convolutional layer applies filters with spatial size (7,
5), stride 2, and standard padding to an input of size (51,113). What will
be the spatial output size?
• Suppose that a two-dimensional convolutional layer is applied with spatial
size (7, 5), stride 2, and standard padding, with 10 input channels and
100 output channels, and no bias terms. What is the number of trainable
parameters in this layer?

Task5
Modify the following code so that it applies batch normalization.
1 class Model(nn.Module):
2
def __init__(self):
3
super(Model, self).__init__()
4
self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)
5
self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)
6
self.maxpool1 = nn.MaxPool2d(kernel_size=2)
7
self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)
8
self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)
2

9
10
11
12
13
14
15
16
17
18
19
20
21

self.maxpool2 = nn.MaxPool2d(kernel_size=2)
self.fc1 = nn.Linear(in_features=32*4*4, out_features=10)
def forward(self, x):
out = F.relu(self.conv1(out))
out = F.relu(self.conv2(out))
out = self.maxpool1(out)
out = F.relu(self.conv3(out))
out = F.relu(self.conv4(out))
out = self.maxpool2(out)
out = out.view(out.size(0), -1)
out = self.fc1(out)
return out

You can but do not need to include unchanged code in your answer. If you do
not include unchanged code, you should make sure that it is clear where code
lines should be included and which lines you propose changing or deleting.

Task 6
Assume the following code should include everything necessary to be applicable
for training a model for one epoch (if is training is True) and evaluating a
validation or test set (if is training is False). You can assume that the user have
defined data loader correctly.
total_loss = 0
for batch_idx, data_batch in enumerate(data_loader):
images = data_batch[0].to('cuda')
labels = data_batch[1].to('cuda')
if not is_training:
with torch.no_grad():
prediction = model(images)
loss = loss_fn(prediction, labels)
total_loss += loss.item()
elif is_training:
prediction = model(images)
loss = loss_fn(prediction, labels)
total_loss += loss.item()
optimizer.zero_grad()
loss.backward()
optimizer.step()
loss_avg = total_loss / len(data_loader)
• If the model applies batch normalization, what needs to be included in
the code so that the batch normalization will work as intended?
3

• Why is this needed?

Task 7
• Name one possible advantage of using a learning rate reduction scheme
over training with a fixed learning rate.
• What can happen when you use a very small constant learning rate ?

Task 8
Consider a dataset for a classification task. It consists of 1000 samples. 970
samples have label A, and the remaining 30 have label B.
• Is accuracy a good metric to evaluate the performance of a classifier on
this dataset?
• If yes, which other metric would you suggest? If not, then which other
metric would be a good choice instead and why?
Explain briefly.

Task 9
Suppose that your loss function depending on parameters w = (w0 , w1 , w2 ) is
L(w) = (3, −1, 2) · w + w02
You perform one step of gradient descent starting at w(0) = (2, 1, 3) with a
learning rate of 0.5.
• What will be the weight w(2) after two steps of the algorithm ?

Task 10
Suppose that you will use a convolution layer as a final layer in an object
detection network in order to predict outputs.
• explain how many outputs it would generate for a given feature map of
the given size (ch = 256, h = 5, w = 6) in the last layer before the output
layer. Note: this may depend on some parameters of your design.

4

Task 11
Suppose you want a model which can recognize bicycles in usual photos showing
them from the side, but also bicycles which are rotated up to 90 degrees such
that they are standing on one wheel.
• How to achieve this when your collected image data has only bicycles in
usual photos showing them from the side?
• How to evaluate performance for your trained model ?

Task 12
• Name possible advantages and potential disadvantages of using MSE loss
to train your network. Try to keep it by at most 6 sentences.

5

