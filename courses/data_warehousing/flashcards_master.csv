id,front,back,source_file,tag
"20260212-1051-23-1","Was ist die Grobdefinition eines Data Warehouse?","Eine für Analysezwecke optimierte zentrale Datenbank, die Daten aus mehreren meist heterogenen Quellen integriert, transformiert und verdichtet","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing definition source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-2","Welches Grundproblem soll Data Warehousing in Unternehmen lösen?","Unternehmen besitzen große Datenmengen, können daraus aber ohne geeignete Aufbereitung oft nicht genug entscheidungsrelevante Informationen ableiten","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing motivation source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-3","Welche vier Kerneigenschaften definiert Inmon für ein Data Warehouse?","<ul><li><strong>Subject-oriented</strong></li><li><strong>Integrated</strong></li><li><strong>Non-volatile</strong></li><li><strong>Time-variant</strong></li></ul>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing inmon source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-4","Was bedeutet subject-oriented im Kontext eines Data Warehouse?","Daten werden themenorientiert über Subjekte wie Kunden, Produkte oder Regionen organisiert statt entlang einzelner operativer Anwendungen","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing inmon-subject-oriented source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-5","Was bedeutet integrated im Kontext eines Data Warehouse?","Daten aus verschiedenen operativen Quellen werden in ein einheitliches, konsistentes Format überführt","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing inmon-integrated source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-6","Was bedeutet non-volatile im Kontext eines Data Warehouse?","Nach dem Laden werden Daten typischerweise nicht mehr laufend durch Update, Delete oder Insert verändert, sondern stabil für Analysen bereitgehalten","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing inmon-non-volatile source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-7","Was bedeutet time-variant im Kontext eines Data Warehouse?","Ein Data Warehouse speichert historisierte Daten mit explizitem Zeitbezug über längere Zeiträume, sodass Zeitreihen- und Vergleichsanalysen möglich werden","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing inmon-time-variant source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-8","Was ist der Kernunterschied zwischen OLTP und OLAP?","<table><thead><tr><th>OLTP</th><th>OLAP</th></tr></thead><tbody><tr><td>Tagesgeschäft und Transaktionen</td><td>Analyse und Entscheidungsunterstützung</td></tr><tr><td>Sehr häufige kurze Zugriffe, auch schreibend</td><td>Moderate Zugriffe auf große Datenmengen, vorwiegend lesend</td></tr><tr><td>Hoher Durchsatz und sehr kurze Antwortzeiten</td><td>Gute Antwortzeiten für komplexe Analysen</td></tr></tbody></table><br><br><div class=""legend"">OLTP: Online Transaction Processing<br>OLAP: Online Analytical Processing</div>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing oltp-vs-olap source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-9","Warum wird ein Data Warehouse oft separat von operativen Datenbanken betrieben?","<ul><li>Unterschiedliche Nutzung und Datenstrukturierung</li><li>Historisierte und konsolidierte Daten sind erforderlich</li><li>Komplexe Analysen sollen operative Transaktionen nicht ausbremsen</li><li>Analytische Systeme benötigen eigenes logisches und physisches Datenmodell</li></ul>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing separation source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-10","Welche Nachteile hat ein separates Data Warehouse laut Einführung?","<ul><li>Datenredundanz</li><li>Daten sind nicht vollständig aktuell</li><li>Hoher Administrationsaufwand</li><li>Hohe Kosten</li></ul>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing tradeoffs source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-11","Welche Hauptbausteine umfasst die Grobarchitektur einer Data-Warehouse-Umgebung?","<ul><li>Datenquellen intern und extern</li><li>Daten-Extraktion, Transformation und Laden in die zentrale Datenbasis</li><li>Zentrales Data Warehouse mit Metadaten</li><li>Data Marts und Cubes</li><li>Front-End für Berichte, Abfragen und Entscheidungsunterstützung</li></ul><br><br><div class=""legend"">ETL: Extract, Transform, Load</div>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing architecture source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-12","Worin unterscheiden sich physische und virtuelle Datenintegration?","<table><thead><tr><th>Physische Integration</th><th>Virtuelle Integration</th></tr></thead><tbody><tr><td>Daten werden vorab in ein Data Warehouse geladen</td><td>Daten bleiben in den Quellen und werden zur Anfragezeit integriert</td></tr><tr><td>Aufbereitung und Bereinigung vorab möglich</td><td>Höhere Quellautonomie, aber Integration zur Laufzeit</td></tr><tr><td>Gut für große Analysevolumina</td><td>Abhängig von Laufzeitverfügbarkeit und Performance der Quellen</td></tr></tbody></table>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing data-integration source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-13","Was sind Kennzahlen und Dimensionen in der mehrdimensionalen Datensicht?","<ul><li><strong>Kennzahlen</strong> sind numerische Fakten als Grundlage für Aggregationen und Berechnungen</li><li><strong>Dimensionen</strong> sind beschreibende Perspektiven wie Zeit, Region oder Branche</li></ul>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing multidimensional-model source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-14","Was unterscheidet Aggregierung von Slicing und Dicing in OLAP-Analysen?","<ul><li><strong>Aggregierung</strong> fasst Kennzahlen über eine oder mehrere Dimensionen zusammen</li><li><strong>Slicing und Dicing</strong> schränken Wertebereiche in Dimensionen gezielt ein</li></ul><br><br><div class=""legend"">OLAP: Online Analytical Processing</div>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing olap-operations source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-15","Was ist der Unterschied zwischen Drill-Down und Roll-Up?","<ul><li><strong>Drill-Down</strong> wechselt zu feineren Detailebenen einer Dimension</li><li><strong>Roll-Up</strong> verdichtet auf höhere, gröbere Hierarchieebenen</li></ul>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing hierarchy-operations source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-16","Wie ist ein Star-Schema aufgebaut?","Eine zentrale Faktentabelle mit Kennzahlen wird über Schlüssel mit jeweils einer Dimensionstabelle pro Analyseperspektive verbunden","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing star-schema source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-17","Wie funktioniert eine typische Star-Join-Anfrage im Star-Schema?","<ol><li>Relevante Dimensionstabellen per Filter einschränken</li><li>Dimensionen sternförmig mit der Faktentabelle joinen</li><li>Kennzahlen per Group By und Aggregation verdichten</li><li>Ergebnisse sortieren oder weiter analysieren</li></ol>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing star-join source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-18","Welche Kernmerkmale nennt die Vorlesung für OLAP?","<ul><li>Interaktive mehrdimensionale Analyse auf konsolidierten Unternehmensdaten</li><li>Skalierbarkeit auf große Datenmengen</li><li>Stabile Antwortzeiten für analytische Abfragen</li><li>Mehrbenutzerunterstützung in Client-Server-Umgebungen</li><li>Dimensionsübergreifende Operationen und Aggregationsebenen</li></ul><br><br><div class=""legend"">OLAP: Online Analytical Processing<br>FASMI: Fast Analysis of Shared Multidimensional Information</div>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing olap-features source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-19","Was beschreibt Knowledge Discovery im Kontext Data Mining?","Eine teilweise automatisierte Wissensextraktion aus Daten durch Kombination von Datenbankverfahren, Statistik und maschinellem Lernen","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing data-mining knowledge-discovery source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1051-23-20","Welche fünf V prägen Big Data laut Einführung?","<ul><li><strong>Volume</strong>: Sehr große Datenmengen</li><li><strong>Velocity</strong>: Hohe Geschwindigkeit von Datenströmen und Analysen</li><li><strong>Variety</strong>: Heterogene strukturierte, teilstrukturierte und unstrukturierte Daten</li><li><strong>Veracity</strong>: Datenqualität und Glaubwürdigkeit</li><li><strong>Value</strong>: Gewinnung nutzbarer Informationen</li></ul>","Kapitel 1 Data Warehouses - Einführung.txt","week-1 ws25-26 data-warehousing big-data source::kapitel-1-data-warehouses---einfuehrung"
"20260212-1104-38-1","Welche Hauptkomponenten umfasst eine typische Data-Warehouse-Referenzarchitektur?","<ul><li>Datenquellen intern und extern</li><li>Monitoring und Ablaufsteuerung</li><li>Extraktion, Transformation und Laden über einen Arbeitsbereich</li><li>Zentrales Data Warehouse</li><li>Abgeleitete Data Marts oder Cubes für Analysen</li><li>Metadaten-Repository</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing referenzarchitektur source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-2","Welche Aufgaben hat der Scheduler in einer Data-Warehouse-Architektur?","<ul><li>Initiiert, steuert und überwacht Prozesse der Datenversorgung</li><li>Startet Extraktion zeitgesteuert, ereignisgesteuert oder manuell</li><li>Dokumentiert Fehler und unterstützt Wiederanlaufmechanismen</li><li>Nutzt Metadaten zur Parametrisierung der Abläufe</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing scheduler source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-3","Welche Qualitätsanforderungen sind an Datenquellen für ein Data Warehouse zentral?","<ul><li>Konsistenz und Korrektheit</li><li>Vollständigkeit</li><li>Aktualität und Verständlichkeit</li><li>Verfügbarkeit relevanter Metadaten</li><li>Praktische Zugriffsmöglichkeiten auf Daten und Änderungen</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing datenquellen source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-4","Wie unterscheiden sich Monitoring-Ansätze für interne und externe Datenquellen?","<ul><li>Interne Quellen nutzen häufig aktive Mechanismen zur Änderungserkennung</li><li>Externe Quellen werden oft per Polling in Intervallen geprüft</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing datenextraktion source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-5","Welche drei grundlegenden Strategien zur Datenextraktion werden in Kapitel 2 gegenübergestellt?","<ul><li>Periodische Snapshots</li><li>Change Data Capture über Zeitstempel</li><li>Change Data Capture über Trigger oder Log-Dateien</li></ul><br><br><div class=""legend"">CDC: Change Data Capture</div>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing extraktionsstrategien source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-6","Was ist der Hauptnachteil von trigger-basiertem Change Data Capture?","<ul><li>Zusätzliche Schreiboperationen belasten die Quell-Datenbank</li><li>Schema-Anpassungen in der Quelle sind erforderlich</li></ul><br><br><div class=""legend"">CDC: Change Data Capture</div>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing cdc-trigger source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-7","Welche Rolle spielt die Staging Area im ETL-Prozess?","Ein temporärer Arbeitsbereich, in dem Daten integriert und bereinigt werden, bevor nur erfolgreich transformierte Daten in das Data Warehouse geladen werden<br><br><div class=""legend"">ETL: Extract, Transform, Load</div>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing staging-area source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-8","Welche typischen Aufgaben umfasst die Datentransformation vor dem Laden?","<ul><li>Data Auditing oder Profiling zur Qualitätsprüfung</li><li>Data Cleaning für fehlerhafte, fehlende oder redundante Werte</li><li>Konsolidierung von Datentypen, Einheiten und Kodierungen</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing transformation source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-9","Was ist ein Data Mart im Verhältnis zum Data Warehouse?","Ein Data Mart ist eine thematisch oder organisatorisch begrenzte Teilmenge des zentralen Data Warehouse für spezifische Analysebedarfe","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing data-mart source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-10","Worin unterscheiden sich abhängige und unabhängige Data Marts?","<table><thead><tr><th>Abhängige Data Marts</th><th>Unabhängige Data Marts</th></tr></thead><tbody><tr><td>Werden aus dem zentralen Warehouse abgeleitet</td><td>Werden direkt aus Quellen aufgebaut</td></tr><tr><td>Höhere Konsistenz mit zentralen Analysen</td><td>Höheres Risiko für Inkonsistenz und Duplikation</td></tr><tr><td>Längere Initialentwicklung wegen zentralem Warehouse</td><td>Schnellere lokale Umsetzung möglich</td></tr></tbody></table>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing data-marts-varianten source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-11","Warum gelten abhängige Data Marts als konsistenter für unternehmensweite Analysen?","Weil sie als kontrollierte Extrakte aus einem gemeinsamen zentralen Datenbestand erzeugt werden","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing abhaengige-data-marts source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-12","Welche zentralen Risiken bringen unabhängige Data Marts mit sich?","<ul><li>Datenredundanz zwischen Data Marts</li><li>Erhöhte Konsistenzprobleme</li><li>Wachsender Integrationsaufwand mit steigender Anzahl von Data Marts</li><li>Erschwerte unternehmensweite Sicht</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing unabhaengige-data-marts source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-13","Welche Funktion hat ein Operational Data Store in der Data-Warehouse-Architektur?","Eine optionale Komponente für operativere, aktuellere Anwendungen auf integrierten Daten mit direkter Änderbarkeit und geringerem Aggregationsgrad<br><br><div class=""legend"">ODS: Operational Data Store</div>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing ods source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-14","Wodurch unterscheiden sich Operational Data Store und Data Warehouse im Analysefokus?","<table><thead><tr><th>Operational Data Store</th><th>Data Warehouse</th></tr></thead><tbody><tr><td>Granulare, aktuelle Daten für operationale Berichte</td><td>Historische, aggregierte Daten für strategische Analysen</td></tr><tr><td>Kurzes Zeitfenster naher Vergangenheit</td><td>Lange Historie</td></tr><tr><td>Häufigeres Laden bis minütlich oder stündlich</td><td>Laden typischerweise täglich bis quartalsweise</td></tr></tbody></table><br><br><div class=""legend"">ODS: Operational Data Store</div>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing ods-vs-dw source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-15","Welche Anforderungen sollte ein Metadaten-Repository in Data-Warehouse-Systemen erfüllen?","<ul><li>Aktuelle Bereitstellung relevanter Metadaten</li><li>Flexible und leistungsfähige Zugriffsschnittstellen</li><li>Unterstützung von Versions- und Konfigurationsverwaltung</li><li>Nutzbarkeit für technische und fachliche Aufgaben</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing metadatenverwaltung source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-16","Was sind technische Metadaten in einer Data-Warehouse-Umgebung?","Metadaten zu Quell- und Zielsystemen, Schemata, technischen Transformations-Mappings, Job-Status und Betriebskennzahlen","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing technische-metadaten source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-17","Was sind fachliche Metadaten in einer Data-Warehouse-Umgebung?","Metadaten zu Geschäftsbegriffen, konzeptuellen Modellen, Kennzahlbedeutungen, Reports sowie Datenherkunft, Richtigkeit und Aktualität","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing fachliche-metadaten source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-18","Was ist der zentrale Modellierungsunterschied zwischen klassischem Data Warehouse und Data Lake?","<table><thead><tr><th>Data Warehouse</th><th>Data Lake</th></tr></thead><tbody><tr><td>Schema first oder Schema on Write</td><td>Schema on Read</td></tr><tr><td>Fokus auf strukturierte Daten</td><td>Unterstützt heterogene inklusive unstrukturierte Daten</td></tr></tbody></table>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing dwh-und-big-data source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-19","Warum ist ein reiner Data Lake laut Kapitel 2 oft nicht ausreichend?","Weil fehlende Datenintegration die effiziente und konsistente Nutzung erschwert und der Lake deshalb meist als Teil einer umfassenderen Architektur eingesetzt wird","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing data-lake source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-20","Was kennzeichnet ein Modern Data Warehouse als Kombination aus Warehouse und Data Lake?","<ul><li>Kombination mehrerer spezialisierter Werkzeuge statt monolithischem System</li><li>Parallele Pipelines je nach Datenart und Analyseanforderung</li><li>Geeignet für weitergehende Analysen über klassische Berichte hinaus</li></ul>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing modern-data-warehouse source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-21","Welche zusätzlichen Ziele verfolgt eine Data-Fabric-Architektur gegenüber klassischen Hybridansätzen?","<ul><li>Einheitlich verwaltete Metadaten über viele Quellen</li><li>Masterdaten-Management</li><li>Stärkere Echtzeit-Datenaufnahme</li><li>Mehr virtuelle Datenanbindung statt reiner Kopien</li></ul><br><br><div class=""legend"">MDM: Master Data Management</div>","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing data-fabric source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1104-38-22","Was ist die Kernidee eines Data Lakehouse und welcher Tradeoff wird genannt?","Ein Data Lakehouse verbindet Lake-Speicherung mit transaktionalen Funktionen für relationale Nutzung, erreicht aber bei Abfragen häufig geringere Geschwindigkeit als klassische Data-Warehouse-Systeme","Kapitel 2 Architektur von Data Warehouse Systemen.txt","week-2 ws25-26 data-warehousing data-lakehouse source::kapitel-2-architektur-von-data-warehouse-systemen"
"20260212-1108-12-1","Was ist eine Kennzahl in der mehrdimensionalen Datenmodellierung?","Eine numerische Größe zur Diagnose, Überwachung und Steuerung, die im Data Warehouse als Fakt oder Measure analysiert wird","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing kennzahlen source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-2","Wie unterscheiden sich additive, semi-additive und nicht-additive Kennzahlen?","<ul><li><strong>Additiv</strong>: über alle relevanten Dimensionen summierbar</li><li><strong>Semi-additiv</strong>: nur über ausgewählte Dimensionen additiv</li><li><strong>Nicht-additiv</strong>: keine sinnvolle Summierung, z.B. Prozentsatz oder Durchschnitt</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing kennzahlenarten source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-3","Welche Aufgabe erfüllen Dimensionen bei der Analyse von Kennzahlen?","Dimensionen geben Kennzahlen ihren fachlichen Kontext, z.B. nach Zeit, Region oder Produkt, und machen Werte dadurch interpretierbar","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing dimensionen source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-4","Wie sind Dimensionen und Kennzahlen im Data Cube abgebildet?","Dimensionen bilden die Koordinaten einer Zelle und Kennzahlen sind die Werte an den Schnittpunkten dieser Koordinaten","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing data-cube source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-5","Wie viele Cuboide besitzt ein n-dimensionaler Cube ohne Dimensionshierarchien?","Ein n-dimensionaler Cube besitzt \\(2^n\\) Cuboide inklusive Basis-Cuboid und Scheitel-Cuboid","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing cuboide-aggregationsgitter source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-6","Was ist der Unterschied zwischen Basis-Cuboid und Scheitel-Cuboid?","<ul><li><strong>Basis-Cuboid</strong>: enthält die detaillierteste n-dimensionale Sicht</li><li><strong>Scheitel-Cuboid</strong>: 0-dimensionale Vollaggregation über alle Dimensionen</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing cuboide source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-7","Was beschreibt ein Aggregationsgitter im Cube-Kontext?","Das Aggregationsgitter ist der Verband aller Cuboide, die aus einem Basis-Cube durch unterschiedliche Aggregationsgrade abgeleitet werden","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing aggregationsgitter source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-8","Welche Eigenschaften haben hierarchische Dimensionen im Data Warehouse?","<ul><li>Sie besitzen Ebenen vom Detailniveau bis zum Top-Level All</li><li>Zwischen den Ebenen bestehen funktionale Abhängigkeiten</li><li>Sie ermöglichen Drill-Down und Roll-Up entlang der Hierarchie</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing dimensionshierarchien source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-9","Was unterscheidet Slice von Dice als Cube-Operation?","<ul><li><strong>Slice</strong>: Selektion auf einer Dimension, meist mit geringerer Dimensionalität</li><li><strong>Dice</strong>: Selektion auf mehreren Dimensionen als Teilwürfel</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing cube-operationen source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-10","Wie unterscheiden sich Drill-Down und Roll-Up innerhalb einer Dimensionshierarchie?","<ul><li><strong>Drill-Down</strong>: Navigation zu detaillierteren Ebenen</li><li><strong>Roll-Up</strong>: Navigation zu stärker aggregierten Ebenen</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing drilldown-rollup source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-11","Welche typische Skalierungsgrenze hat die direkte multidimensionale Speicherung in MOLAP?","Die Zahl möglicher Zellen wächst mit dem Kreuzprodukt der Dimensionskardinalitäten sehr stark, wodurch große Cubes schwer skalierbar werden<br><br><div class=""legend"">MOLAP: Multidimensional Online Analytical Processing</div>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing molap source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-12","Wie geht MOLAP mit dünn besetzten Cubes um?","Typisch ist die Aufteilung in speicherpassende Sub-Cubes oder Chunks mit zweistufiger Adressierung über Chunk-ID und Zelle im Chunk<br><br><div class=""legend"">MOLAP: Multidimensional Online Analytical Processing</div>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing molap-speicherung source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-13","Wofür wird MDX im Data-Warehouse-Umfeld verwendet?","MDX dient zur Abfrage multidimensional gespeicherter Cubes und zur Auswahl aggregierter Sub-Cubes über Achsen und Slicer<br><br><div class=""legend"">MDX: Multidimensional Expressions</div>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing mdx source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-14","Welche Kernteile enthält eine MDX-SELECT-Anfrage?","<ul><li>Achsenspezifikationen wie rows und columns</li><li>Die Cube-Quelle im FROM-Teil</li><li>Optional einen Slicer im WHERE-Teil zur Werteauswahl</li></ul><br><br><div class=""legend"">MDX: Multidimensional Expressions</div>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing mdx-abfragen source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-15","Welche Grundidee verfolgt ROLAP bei mehrdimensionalen Daten?","ROLAP speichert Fakten und Dimensionen relational in Tabellen und bildet mehrdimensionale Analysen über SQL-Joins und Aggregationen ab<br><br><div class=""legend"">ROLAP: Relational Online Analytical Processing</div>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing rolap source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-16","Warum ist ein Star-Schema in ROLAP oft besser als ein vollständig normalisiertes Schema?","Dimensionen sind im Star-Schema meist denormalisiert, wodurch analytische Anfragen mit weniger Joins und geringerer Komplexität formuliert werden können<br><br><div class=""legend"">ROLAP: Relational Online Analytical Processing</div>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing star-schema-rolap source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-17","Was ist der zentrale Tradeoff des Snowflake-Schemas gegenüber dem Star-Schema?","Das Snowflake-Schema reduziert Redundanz durch normalisierte Dimensionen, erhöht aber den Join-Aufwand und damit die Zugriffskosten","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing snowflake-schema source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-18","Was kennzeichnet ein Galaxien-Schema im Data Warehouse?","Ein Galaxien-Schema kombiniert mehrere Faktentabellen, die gemeinsame Dimensionstabellen nutzen und damit mehrere Analysebereiche in einer Fact-Constellation verbinden","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing galaxien-schema source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-19","Wie läuft eine typische SQL-Star-Join-Auswertung ab?","<ol><li>Dimensionstabellen und Faktentabelle über Schlüssel verbinden</li><li>Dimensionen per WHERE filtern</li><li>Kennzahlen aggregieren</li><li>Über die gewünschten Analyseattribute gruppieren</li></ol>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing sql-star-join source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-20","Was bewirkt GROUP BY CUBE in SQL?","GROUP BY CUBE erzeugt für n Attribute alle \\(2^n\\) Gruppierungskombinationen inklusive Vollaggregation","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing group-by-cube source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-21","Was ist der Unterschied zwischen GROUP BY CUBE und GROUP BY ROLLUP?","<table><thead><tr><th>CUBE</th><th>ROLLUP</th></tr></thead><tbody><tr><td>Inter-dimensionale Aggregation über alle Kombinationen</td><td>Intra-dimensionale Hierarchieaggregation entlang einer Attributreihenfolge</td></tr><tr><td>Erzeugt bei n Attributen \\(2^n\\) Gruppen</td><td>Erzeugt bei n Attributen \\(n+1\\) Gruppen</td></tr></tbody></table>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing cube-vs-rollup source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-22","Wofür nutzt man GROUPING SETS in SQL-Analysen?","GROUPING SETS erlaubt mehrere explizit definierte Gruppierungen in einer einzigen Anfrage, ohne alle Kombinationen eines vollständigen Cubes zu berechnen","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing grouping-sets source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-23","Worin unterscheiden sich RANK und DENSE_RANK bei SQL-Rangfolgen?","<ul><li><strong>RANK</strong> lässt Rangnummern nach Gleichstand aus</li><li><strong>DENSE_RANK</strong> vergibt lückenlose Rangnummern</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing rank-window-queries source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1108-12-24","Welche Kernbausteine hat eine SQL-Window-Query mit OVER?","<ul><li>Optional PARTITION BY zur Aufteilung in Teilsequenzen</li><li>Optional ORDER BY zur Reihenfolge innerhalb einer Sequenz</li><li>Optionales Fenster mit ROWS oder RANGE, z.B. für gleitende Mittelwerte oder kumulierte Summen</li></ul>","Kapitel 3 Mehrdimensio___enmodellierung und Operationen.txt","week-3 ws25-26 data-warehousing window-queries source::kapitel-3-mehrdimensio___enmodellierung-und-operationen"
"20260212-1117-26-1","Warum gilt ETL im Data Warehousing als materialisierter Integrationsansatz?","Weil Daten aus Quellen extrahiert, transformiert und als physische integrierte Datenbasis für Analysen im Warehouse gespeichert werden","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing etl-ueberblick source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-2","Welche drei Hauptphasen umfasst der ETL-Prozess?","<ul><li><strong>Extraktion</strong>: Auswahl und Übernahme von Quelldaten</li><li><strong>Transformation</strong>: Anpassung an Zielschema und Qualitätsregeln</li><li><strong>Laden</strong>: physisches Einbringen in das Data Warehouse</li></ul><br><br><div class=""legend"">ETL: Extract, Transform, Load</div>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing etl-phasen source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-3","Warum hat ETL einen direkten Einfluss auf die Qualität späterer Analysen?","Fehlerhafte oder inkonsistente Eingabedaten werden ohne wirksame ETL-Bereinigung in Analysen fortgeschrieben, sodass Entscheidungen auf verzerrten Ergebnissen basieren","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing etl-qualitaet source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-4","Wie unterscheiden sich ETL und ELT im Integrationsablauf?","<table><thead><tr><th>ETL</th><th>ELT</th></tr></thead><tbody><tr><td>Transformiert vor dem Laden ins Zielsystem</td><td>Lädt zuerst und transformiert danach</td></tr><tr><td>Stark klassisch für Data Warehouse</td><td>Häufig im Data-Lake-Umfeld eingesetzt</td></tr></tbody></table>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing etl-vs-elt source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-5","Auf welchen zwei Ebenen integriert ETL Daten laut Kapitel 4?","<ul><li>Schemaintegration mit Abgleich der Strukturen und Begriffe</li><li>Datenintegration mit Bereinigung und Zusammenführung der Instanzdaten</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing etl-integrationsebenen source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-6","Welche Kernanforderungen werden an eine Schemaintegration gestellt?","<ul><li><strong>Minimalität</strong>: keine überflüssige Redundanz</li><li><strong>Korrektheit</strong>: semantisch korrekte und konsistente Integration</li><li><strong>Verständlichkeit</strong> des integrierten Schemas</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing schemaintegration-anforderungen source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-7","Was ist der Kernunterschied zwischen Bottom-Up- und Top-Down-Schemaintegration?","<table><thead><tr><th>Bottom-Up</th><th>Top-Down</th></tr></thead><tbody><tr><td>Globales Schema entsteht durch Mischen der Quellschemata</td><td>Globales Schema ist vorgegeben und Quellen werden darauf gemappt</td></tr><tr><td>Neue Quellen ändern oft das globale Schema</td><td>Jede Quelle wird separat gegen das Zielschema abgeglichen</td></tr></tbody></table>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing bottom-up-vs-top-down source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-8","Warum ist Top-Down-Integration für Data-Warehouse-Projekte oft pragmatisch?","Weil das Zielschema fachlich vorgegeben ist und nicht alle Teile aller Quellschemata vollständig global integriert werden müssen","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing top-down-integration source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-9","Welche Formen semantischer Heterogenität treten bei Schemata typischerweise auf?","<ul><li>Namenskonflikte wie Synonyme und Homonyme</li><li>Strukturelle Konflikte bei Entitäten, Attributen oder Schlüsseln</li><li>Unterschiedliche Modellierungstiefe und Realitätsausschnitte</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing semantische-heterogenitaet source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-10","Warum ist vollautomatische Schemaintegration laut Vorlesung nicht realistisch?","Semantische Mehrdeutigkeit und begrenzte Aussagekraft reiner Metadaten erfordern Nutzerfeedback und damit mindestens semi-automatische Verfahren","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing schemaintegration-automatisierung source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-11","Was ist das Ziel von Schema Matching?","Schema Matching bestimmt semantische Korrespondenzen zwischen Elementen verschiedener Schemata, optional mit Ähnlichkeitswerten und Beziehungstypen","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing schema-matching source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-12","Welche Informationen können als Eingabe für Schema Matching genutzt werden?","<ul><li>Schema-Informationen</li><li>Instanzbeispiele</li><li>Hintergrundwissen wie Wörterbücher oder Thesauri</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing schema-matching-input source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-13","Welche Hauptklassen von Matching-Verfahren nennt Kapitel 4?","<ul><li>Linguistische Verfahren</li><li>Strukturelle Verfahren</li><li>Instanzbasierte Verfahren</li><li>Kombinierte Matcher-Ansätze</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing schema-matching-verfahren source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-14","Wie ist die normalisierte Edit-Distance-Ähnlichkeit zwischen zwei Strings definiert?","Als \\(\\text{sim}_{edit}(a,b)=1-\\frac{dist(a,b)}{\\max(|a|,|b|)}\\), wobei \\(dist\\) die minimale Zahl aus Einfügen, Löschen und Ersetzen ist","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing edit-distance source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-15","Was ist die Grundidee von q-Gram-basiertem Schema Matching?","Strings werden in überlappende Teilstrings fester Länge zerlegt und über deren Überlappung mit Mengenähnlichkeiten wie Dice oder Jaccard verglichen","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing q-gram-matching source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-16","Welche drei Schritte umfasst Data Cleaning laut Kapitel 4?","<ol><li>Datenanalyse oder Profiling zur Fehlererkennung</li><li>Definition von Mapping-Regeln und Transformations-Workflows</li><li>Regelmäßige Transformation und Bereinigung der Daten</li></ol>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing data-cleaning-ablauf source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-17","Welche Datenqualitätsprobleme unterscheidet man bei Data Cleaning grundsätzlich?","<table><thead><tr><th>Single-Source</th><th>Multi-Source</th></tr></thead><tbody><tr><td>Fehler innerhalb einer Quelle, z.B. Tippfehler oder fehlende Werte</td><td>Konflikte zwischen Quellen, z.B. widersprüchliche Repräsentationen</td></tr><tr><td>Auf Schema- und Instanzebene möglich</td><td>Ebenfalls auf Schema- und Instanzebene möglich</td></tr></tbody></table>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing data-cleaning-probleme source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-18","Welche typischen Teilaufgaben umfasst Data Cleaning auf Instanzebene?","<ul><li>Standardisierung von Formaten und Kodierungen</li><li>Parsing und Attribut-Splitting aus Freitextwerten</li><li>Validierung mit Referenzwissen und Regeln</li><li>Korrektur fehlender oder inkonsistenter Werte</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing data-cleaning-teilaufgaben source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-19","Was ist Entity Matching im ETL-Kontext?","Entity Matching identifiziert Datensätze, die dieselbe reale Entität beschreiben, trotz unterschiedlicher Schreibweisen oder Quellenrepräsentationen","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing entity-matching source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-20","Warum ist Blocking für skalierbares Entity Matching notwendig?","Weil nicht alle Satzpaare verglichen werden müssen, sondern nur Kandidaten innerhalb relevanter Blöcke, wodurch der quadratische Vergleichsaufwand stark sinkt","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing blocking source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-21","Was ist der Tradeoff bei der Wahl der Blockgröße im Blocking?","<ul><li>Kleine Blöcke sparen viele Vergleiche, riskieren aber verpasste Matches</li><li>Größere oder mehrfache Blockings erhöhen Match-Abdeckung, kosten aber mehr Laufzeit</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing blocking-tradeoff source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-22","Welche zwei Kernmetriken bewertet man bei Blocking-Verfahren?","<ul><li><strong>Reduction Rate (RR)</strong>: Anteil eingesparter Vergleiche</li><li><strong>Pairs Completeness (PC)</strong>: Anteil wahrer Match-Paare, die im Blocking erhalten bleiben</li></ul>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing blocking-metriken source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-23","Welche Grundansätze gibt es für den Matching-Schritt nach dem Blocking?","<ul><li>Regelbasiertes Matching mit Schwellwerten</li><li>Überwachtes ML-Matching mit Trainingsdaten</li><li>Kombination mehrerer Attributähnlichkeiten und Kontextmerkmale</li></ul><br><br><div class=""legend"">ML: Machine Learning</div>","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing matching-verfahren source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-24","Welche Aufgabe erfüllt Entity Clustering nach dem Matching?","Entity Clustering gruppiert zusammengehörige Match-Paare in Cluster pro realer Entität und schafft damit die Basis für konsistente Datenfusion","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing entity-clustering source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1117-26-25","Warum kann transitive Hüllenbildung bei Entity Clustering problematisch sein?","Connected-Component-Clustering kann große Cluster mit nur schwach ähnlichen Datensätzen erzeugen, wenn einzelne Match-Links fehlerhaft sind","Kapitel 4  ETL - Datenvorverarbeitung und -integration.txt","week-4 ws25-26 data-warehousing clustering-risiken source::kapitel-4--etl---datenvorverarbeitung-und--integration"
"20260212-1125-54-1","Warum sind in Data-Warehouse-Systemen spezielle Performance-Techniken nötig?","Weil sehr große Faktentabellen, mehrdimensionale Filter und Aggregationen mit vielen Nutzern sonst zu unakzeptablen Antwortzeiten führen","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing performance-techniken source::kapitel-5-performance-techniken"
"20260212-1125-54-2","Wie unterscheiden sich ein- und mehrdimensionale Indexstrukturen im Einsatzzweck?","<table><thead><tr><th>Eindimensional</th><th>Mehrdimensional</th></tr></thead><tbody><tr><td>Optimiert für ein Attribut oder eine Attributkombination</td><td>Optimiert für gleichzeitige Bedingungen auf mehreren Dimensionen</td></tr><tr><td>Gut für Punkt- und Bereichsanfragen in einer Ordnung</td><td>Bessere Raumbegrenzung bei multidimensionalen Anfragen</td></tr></tbody></table>","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing indexstrukturen source::kapitel-5-performance-techniken"
"20260212-1125-54-3","Warum reichen klassische eindimensionale B-Baum-Indizes bei multidimensionalen Abfragen oft nicht aus?","Sie begrenzen den Suchraum nur eingeschränkt für kombinierte Bedingungen über mehrere Dimensionen, sodass unnötig viele Datenseiten gelesen werden","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing eindimensionale-indizes source::kapitel-5-performance-techniken"
"20260212-1125-54-4","Was bedeutet eindimensionale Einbettung mehrdimensionaler Daten?","Mehrdimensionale Punkte werden über eine raumfüllende Kurve in eine eindimensionale Ordnung überführt, um sie mit eindimensionalen Indexstrukturen effizient zu verwalten","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing eindimensionale-einbettung source::kapitel-5-performance-techniken"
"20260212-1125-54-5","Was ist das Ziel von Space-Filling-Curves wie Z- oder Hilbert-Kurve bei der Indexierung?","Sie sollen räumliche Nachbarschaft in eine lineare Reihenfolge übertragen, damit Bereichsanfragen möglichst wenige zusammenhängende Indexbereiche lesen","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing space-filling-curves source::kapitel-5-performance-techniken"
"20260212-1125-54-6","Wie arbeitet ein UB-Baum bei mehrdimensionalen Bereichsanfragen?","Er bildet Punkte auf Z-Werte ab, indexiert diese in einem geclusterten B-Baum und durchsucht für eine Bereichsanfrage die relevanten Z-Regionen","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing ub-baum source::kapitel-5-performance-techniken"
"20260212-1125-54-7","Was ist ein Standard-Bitlisten-Index?","Für jeden Attributwert existiert ein Bitvektor mit einem Bit pro Tupel, das markiert, ob das Tupel diesen Wert besitzt","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing bitlisten-index source::kapitel-5-performance-techniken"
"20260212-1125-54-8","Wann sind Bitlisten-Indizes besonders wirksam?","Bei Attributen mit kleiner Wertemenge und geringer Selektivität, weil boolesche Verknüpfungen der Bitlisten viele Datenzugriffe vermeiden","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing bitlisten-einsatz source::kapitel-5-performance-techniken"
"20260212-1125-54-9","Wie unterstützen Bitlisten-Indizes mehrdimensionale Filterbedingungen?","Mehrere Bedingungen werden per AND, OR und NOT direkt auf Bitvektoren kombiniert und liefern so schnell die relevanten Tupelpositionen","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing bitlisten-boolesche-operationen source::kapitel-5-performance-techniken"
"20260212-1125-54-10","Was ist die Idee eines Bitlisten-Join-Index im Star-Schema?","Dimensionsattribute werden als Bitlisten direkt auf Faktentupel abgebildet, sodass Join-Ergebnisse für Filterbedingungen effektiv vorweggenommen werden","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing bitlisten-join-index source::kapitel-5-performance-techniken"
"20260212-1125-54-11","Welchen Vorteil haben bereichskodierte Bitlisten bei Bereichsanfragen?","Sie kodieren kleiner-gleich-Beziehungen pro Wert, sodass typische Bereichsbedingungen mit höchstens zwei Bitlisten auswertbar sind","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing bereichskodierte-bitlisten source::kapitel-5-performance-techniken"
"20260212-1125-54-12","Was ist der Kernnutzen intervallkodierter Bitlisten-Indizes?","Sie reduzieren den Speicherbedarf durch Intervallkodierung und beantworten Punkt- und Bereichsanfragen weiterhin mit sehr wenigen Bitlisten","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing intervallkodierte-bitlisten source::kapitel-5-performance-techniken"
"20260212-1125-54-13","Was bedeutet kodierte Bitlisten-Indexierung mit logarithmischer Kodierung?","Statt eine Bitliste pro Wert werden nur logarithmisch viele Bitlisten genutzt, indem Werte über Bitmuster kodiert werden","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing kodierte-bitlisten source::kapitel-5-performance-techniken"
"20260212-1125-54-14","Worin liegt der strukturelle Unterschied zwischen Row Store und Column Store?","<table><thead><tr><th>Row Store</th><th>Column Store</th></tr></thead><tbody><tr><td>Speichert Tupel zeilenweise zusammen</td><td>Speichert Attribute spaltenweise getrennt</td></tr><tr><td>Günstig für viele schreibende Tupeloperationen</td><td>Günstig für analytische Abfragen auf wenigen Spalten</td></tr></tbody></table>","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing row-vs-column-store source::kapitel-5-performance-techniken"
"20260212-1125-54-15","Warum beschleunigt ein Column Store viele OLAP-Abfragen?","Weil nur benötigte Spalten gelesen und oft komprimiert verarbeitet werden, was I/O reduziert und Aggregationen effizienter macht<br><br><div class=""legend"">OLAP: Online Analytical Processing</div>","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing column-store-vorteile source::kapitel-5-performance-techniken"
"20260212-1125-54-16","Welche typischen Nachteile hat ein Column Store gegenüber einem Row Store?","Einfügen und Aktualisieren ganzer Tupel über viele Attribute ist aufwendiger und damit für transaktionslastige Workloads meist weniger geeignet","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing column-store-nachteile source::kapitel-5-performance-techniken"
"20260212-1125-54-17","Welche Rolle spielt Datenkompression in Column Stores?","Sie senkt Speicherbedarf und I/O-Kosten und ermöglicht in vielen Fällen Operationen direkt auf komprimierten Repräsentationen","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing datenkompression source::kapitel-5-performance-techniken"
"20260212-1125-54-18","Wann ist Run-Length-Encoding für Data-Warehouse-Spalten besonders effektiv?","Bei langen Folgen gleicher Werte, insbesondere wenn die Spalte sortiert ist und gleiche Werte dadurch zusammenhängend auftreten","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing rle source::kapitel-5-performance-techniken"
"20260212-1125-54-19","Wofür eignet sich Wörterbuch-Kodierung bei der Spaltenkompression?","Für Attribute mit wiederkehrenden oft längeren Werten, die durch kurze Codes ersetzt und bei Bedarf per Lookup dekodiert werden","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing dictionary-encoding source::kapitel-5-performance-techniken"
"20260212-1125-54-20","Was ist der Unterschied zwischen vertikaler und horizontaler Fragmentierung von Relationen?","<table><thead><tr><th>Vertikal</th><th>Horizontal</th></tr></thead><tbody><tr><td>Zerlegung nach Attributen per Projektion</td><td>Zerlegung nach Tupeln per Selektionsprädikaten</td></tr><tr><td>Rekonstruktion über Join</td><td>Rekonstruktion über Vereinigung der Fragmente</td></tr></tbody></table>","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing fragmentierung source::kapitel-5-performance-techniken"
"20260212-1125-54-21","Welchen Nutzen hat horizontale Fragmentierung für Data-Warehouse-Abfragen?","Sie beschränkt Anfragen auf relevante Tupelbereiche und erlaubt die parallele Verarbeitung disjunkter Fragmente","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing horizontale-fragmentierung source::kapitel-5-performance-techniken"
"20260212-1125-54-22","Was ist mehrdimensionale hierarchische Fragmentierung im Star-Schema?","Eine reihenfolgeunabhängige Bereichsfragmentierung über ausgewählte Dimensionsattribute, die viele Anfragen auf wenige relevante Fragmente begrenzt","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing mdhf source::kapitel-5-performance-techniken"
"20260212-1125-54-23","Wozu werden materialisierte Sichten im Data Warehouse verwendet?","Zur expliziten Vorberechnung und Speicherung häufiger Anfrageergebnisse oder Aggregationen, um Antwortzeiten deutlich zu senken","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing materialisierte-sichten source::kapitel-5-performance-techniken"
"20260212-1125-54-24","Was bedeutet Query Rewrite bei materialisierten Sichten?","Der Optimierer ersetzt eine Anfrage transparent durch eine äquivalente Form, die auf vorhandene materialisierte Sichten zugreift","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing query-rewrite source::kapitel-5-performance-techniken"
"20260212-1125-54-25","Worin unterscheidet sich die statische von der dynamischen Auswahl materialisierter Sichten?","<table><thead><tr><th>Statisch</th><th>Dynamisch</th></tr></thead><tbody><tr><td>Vordefiniert bis zur nächsten Aktualisierung</td><td>Laufzeitnahes Caching anhand aktueller Anfragen</td></tr><tr><td>Einfacher zu verwalten</td><td>Flexibler, aber mit komplexeren Verdrängungsentscheidungen</td></tr></tbody></table>","Kapitel 5 Performance-Techniken.txt","week-5 ws25-26 data-warehousing auswahl-materialisierter-sichten source::kapitel-5-performance-techniken"
"20260212-1152-00-1","Was ist das Ziel von Knowledge Discovery in Databases (KDD)?","Die semi-automatische Gewinnung statistisch gültiger, zuvor unbekannter und potenziell nützlicher Muster aus Daten","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing kdd-prozess source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-2","Welche Hauptphasen umfasst der KDD-Prozess in der Vorlesung?","<ol><li>Selektion der relevanten Daten</li><li>Vorverarbeitung und Transformation</li><li>Data Mining zur Mustererkennung</li><li>Interpretation und Bewertung der Ergebnisse</li></ol>","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing kdd-phasen source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-3","Wie grenzt die Vorlesung Data Mining von maschinellem Lernen ab?","Data Mining fokussiert die effiziente Mustererkennung in großen Datenmengen, während maschinelles Lernen lernbasierte Modelle für Vorhersagen und Wissensgenerierung bereitstellt","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing data-mining-vs-ml source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-4","Warum ist Datenvorverarbeitung vor Data-Mining- oder ML-Verfahren zentral?","Weil Diskretisierung, Feature-Extraktion und Ableitung aussagekräftiger Attribute die Musterqualität und Generalisierbarkeit entscheidend verbessern","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing datenvorverarbeitung-ml source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-5","Welche drei Verfahrensklassen stehen im Zentrum von Kapitel 6?","<ul><li>Assoziationsregeln</li><li>Clusteranalyse</li><li>Klassifikation</li></ul>","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing verfahrensklassen source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-6","Was beschreibt eine Assoziationsregel in der Warenkorbanalyse?","Eine Regel \\(X \\to Y\\), die ausdrückt, dass das gemeinsame Auftreten von Items in \\(X\\) mit dem Auftreten von Items in \\(Y\\) zusammenhängt","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing assoziationsregeln source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-7","Wie ist der Support einer Assoziationsregel definiert?","Als Anteil der Transaktionen, die sowohl die Items aus Regelrumpf als auch Regelkopf enthalten","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing support source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-8","Wie ist die Konfidenz einer Assoziationsregel \\(X \\to Y\\) definiert?","Als bedingter Anteil der Transaktionen mit \\(X\\), die zusätzlich auch \\(Y\\) enthalten","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing konfidenz source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-9","Welche Kernidee nutzt der A-Priori-Algorithmus zur Kandidatenreduktion?","Die Anti-Monotonie häufiger Itemsets: Ist eine Menge häufig, sind alle Teilmengen häufig, und ist eine Menge selten, sind alle Obermengen selten","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing apriori-idee source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-10","Wie arbeitet der A-Priori-Algorithmus grundsätzlich iterativ?","Er bestimmt zunächst häufige 1-Itemsets und erzeugt daraus schrittweise größere Kandidatenmengen, die per Support-Schwelle gepruned werden","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing apriori-ablauf source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-11","Warum kann A-Priori bei großen Itemmengen teuer werden?","Weil die Zahl der Kandidatenkombinationen mit wachsender Itemset-Größe stark ansteigt und viele Support-Prüfungen erfordert","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing apriori-limits source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-12","Was ist die Grundidee von Frequent-Pattern-Trees (FP-Trees)?","Transaktionen werden in einer kompakten Baumstruktur mit gemeinsamen Präfixen gespeichert, sodass häufige Muster ohne explizite Kandidatengenerierung gefunden werden","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing fp-tree-grundidee source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-13","Wie entsteht ein FP-Tree aus Transaktionsdaten?","Nach Bestimmung häufiger Items werden Transaktionen in Häufigkeitsreihenfolge als Pfade eingefügt, wobei gemeinsame Präfixe verdichtet und Zähler erhöht werden","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing fp-tree-erzeugung source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-14","Wie findet FP-Growth häufige Itemsets im FP-Tree?","Durch rekursive Divide-and-Conquer-Auswertung über Musterbasen und reduzierte bedingte FP-Bäume pro Suffix-Item","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing fp-growth source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-15","Welches Ziel verfolgt Clusteranalyse im Kapitel 6?","Objekte so zu segmentieren, dass sie innerhalb eines Clusters möglichst ähnlich und zwischen Clustern möglichst unähnlich sind","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing clusteranalyse-ziel source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-16","Was sind die Eingaben und Schritte des k-Means-Algorithmus?","<ul><li>Vorgegeben sind Distanzfunktion und Clusteranzahl \\(k\\)</li><li>Zufällige Initialisierung der Zentren</li><li>Iterative Zuordnung der Punkte zum nächsten Zentrum</li><li>Neuberechnung der Zentren bis zur Konvergenz</li></ul>","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing k-means-ablauf source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-17","Welche zwei zentralen Schwächen von k-Means nennt die Vorlesung?","Konvergenz zu lokalen Minima und hoher Aufwand für wiederholte Distanzberechnungen","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing k-means-nachteile source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-18","Welche Idee verfolgt Canopy Clustering?","Es bildet schnell überlappende Vorcluster mit zwei Distanzschwellen und dient häufig als skalierbarer Pre-Clustering-Schritt","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing canopy-clustering source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-19","Wie wirken die beiden Schwellen \\(T_1\\) und \\(T_2\\) beim Canopy Clustering zusammen?","<ul><li>Punkte innerhalb \\(T_1\\) werden einem Canopy zugeordnet</li><li>Punkte innerhalb des strengeren \\(T_2\\) werden zusätzlich aus der Kandidatenliste entfernt</li></ul>","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing canopy-parameter source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-20","Wie ist das Klassifikationsproblem formal im Kapitel beschrieben?","Aus Trainingsobjekten mit bekannter Klasse wird ein Klassifikator gelernt, der neuen Objekten aus \\(D\\setminus O\\) eine Klasse aus der Zielmenge zuordnet","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing klassifikationsprozess source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-21","Welche zwei Hauptschritte umfasst ein überwachter Klassifikationsprozess?","<ol><li>Konstruktion eines Modells auf Trainingsdaten</li><li>Anwendung des Modells zur Vorhersage auf unbekannte Daten</li></ol>","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing klassifikation-schritte source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-22","Wie wird ein Entscheidungsbaum für Klassifikation genutzt?","Ein Objekt durchläuft den Baum top-down entlang der Attributtests bis zu einem Blatt, dessen Klasse als Vorhersage dient","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing entscheidungsbaum-nutzung source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-23","Nach welchem Prinzip werden Split-Attribute beim Lernprozess von Entscheidungsbäumen gewählt?","Typischerweise nach maximalem Informationsgewinn, gemessen z.B. über Entropie-basierte Kriterien","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing entscheidungsbaum-split source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-24","Was kennzeichnet neuronale Netze im Klassifikationskontext?","Mehrschichtige Netze aus verbundenen Neuronen mit gewichteten Kanten, die komplexe nichtlineare Zusammenhänge zwischen Eingaben und Klassen lernen","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing neuronale-netze source::kapitel-6-ueberblick-data-miningml"
"20260212-1152-00-25","Warum ist Deep Learning besonders für unstrukturierte Daten relevant?","Weil tiefe Netze aus großen Trainingsmengen geeignete Repräsentationen lernen und damit Aufgaben auf Bildern, Sprache oder Texten leistungsfähig lösen","Kapitel 6 Überblick Data MiningML.txt","week-6 ws25-26 data-warehousing deep-learning source::kapitel-6-ueberblick-data-miningml"
