"<p>Was ist das Ziel von Clustering?</p>","<p>Datenpunkte so zu gruppieren, dass die paarweisen Distanzen <strong>innerhalb eines Clusters klein</strong> und <strong>zwischen verschiedenen Clustern groß</strong> sind.</p>","week-2 ws-25-26 clustering objective data-mining source::kapitel-2-folien"
"<p>Wie ist die euklidische Distanz zwischen zwei Punkten definiert?</p>","<p>\(d(x_i, x_j) = \sqrt{\sum_{k=1}^{d} (x_{ik} - x_{jk})^2}\)</p>","week-2 ws-25-26 distance-metrics clustering data-mining source::kapitel-2-folien"
"<p>Wie ist die Manhattan-Distanz zwischen zwei Punkten definiert?</p>","<p>\(d(x_i, x_j) = \sum_{k=1}^{d} |x_{ik} - x_{jk}|\)</p>","week-2 ws-25-26 distance-metrics clustering data-mining source::kapitel-2-folien"
"<p>Wann ist eine direkte Visualisierung von Clustering-Ergebnissen möglich?</p>","<p>Nur bei <strong>zwei Dimensionen</strong>.</p>","week-2 ws-25-26 clustering visualization data-mining source::kapitel-2-folien"
"<p>Was ist der Interquartilsabstand (IQR) in einem Boxplot?</p>","<p>\(\text{IQR} = Q3 - Q1\)</p>","week-2 ws-25-26 boxplot visualization data-mining source::kapitel-2-folien"
"<p>Wie werden die Whiskers in einem Boxplot definiert?</p>","<ul><li>Unterer Whisker: <strong>Q1 - 1,5*IQR</strong></li><li>Oberer Whisker: <strong>Q3 + 1,5*IQR</strong></li><li>Endet am <strong>letzten Datenpunkt</strong> innerhalb des Bereichs</li></ul>","week-2 ws-25-26 boxplot visualization data-mining source::kapitel-2-folien"
"<p>Wann gilt ein Datenpunkt im Boxplot als Ausreißer?</p>","<p>Wenn er <strong>außerhalb der Whiskers</strong> liegt.</p>","week-2 ws-25-26 boxplot visualization data-mining source::kapitel-2-folien"
"<p>Warum ist Clustering für große Datenmengen rechnerisch anspruchsvoll?</p>","<ul><li><strong>Kombinatorisch:</strong> \(k^N\) mögliche Zuordnungen</li><li><strong>Paarweise Vergleiche:</strong> \(O(N^2)\) Ähnlichkeitsberechnungen</li></ul>","week-2 ws-25-26 clustering complexity data-mining source::kapitel-2-folien"
"<p>Was besagt der Fluch der hohen Dimensionen für Distanzen?</p>","<p>In sehr hohen Dimensionen haben <strong>fast alle Paare</strong> von Datenpunkten eine <strong>ähnliche Distanz</strong>.</p>","week-2 ws-25-26 curse-of-dimensionality clustering data-mining source::kapitel-2-folien"
"<p>Was ist der Unterschied zwischen agglomerativem und divisivem hierarchischem Clustering?</p>","<table><thead><tr><th>Agglomerativ</th><th>Divisiv</th></tr></thead><tbody><tr><td>Start mit <strong>Einzelpunkten</strong></td><td>Start mit <strong>einem Cluster</strong></td></tr><tr><td>Cluster werden <strong>zusammengeführt</strong></td><td>Cluster werden <strong>aufgeteilt</strong></td></tr></tbody></table>","week-2 ws-25-26 hierarchical-clustering clustering data-mining source::kapitel-2-folien"
"<p>Was zeigt ein Dendrogramm in der hierarchischen Clusteranalyse?</p>","<ul><li><strong>Blätter</strong> repräsentieren Datenpunkte</li><li><strong>Höhe</strong> der Vereinigung gibt die Cluster-Distanz an</li></ul>","week-2 ws-25-26 hierarchical-clustering dendrogram data-mining source::kapitel-2-folien"
"<p>Welche zwei grundlegenden Entscheidungen sind für hierarchische Clusteranalyse nötig?</p>","<ul><li><strong>Distanzdefinition</strong> zwischen Clustern</li><li><strong>Stoppregel</strong></li></ul>","week-2 ws-25-26 hierarchical-clustering clustering data-mining source::kapitel-2-folien"
"<p>Wie definieren die gängigen Linkage-Methoden die Distanz zwischen zwei Clustern?</p>","<table><thead><tr><th>Linkage</th><th>Definition</th></tr></thead><tbody><tr><td>Single</td><td>Minimale paarweise Distanz</td></tr><tr><td>Complete</td><td>Maximale paarweise Distanz</td></tr><tr><td>Average</td><td>Durchschnittliche paarweise Distanz</td></tr><tr><td>Centroid</td><td>Distanz der Centroiden</td></tr><tr><td>Ward</td><td>Zunahme der Varianz beim Zusammenführen</td></tr></tbody></table>","week-2 ws-25-26 linkage hierarchical-clustering data-mining source::kapitel-2-folien"
"<p>Welche Linkage-Methoden sind direkt in nicht-euklidischen Räumen anwendbar?</p>","<p><strong>Single</strong>, <strong>Complete</strong> und <strong>Average</strong> Linkage.</p>","week-2 ws-25-26 linkage hierarchical-clustering data-mining source::kapitel-2-folien"
"<p>Warum sind Centroid- und Ward-Linkage nicht immer direkt anwendbar?</p>","<p>Sie benötigen einen <strong>Centroiden</strong>, der in manchen Räumen (z. B. <strong>Strings</strong>) nicht direkt definiert ist.</p>","week-2 ws-25-26 linkage hierarchical-clustering data-mining source::kapitel-2-folien"
"<p>Was sind typische Stoppregeln bei agglomerativem Clustering?</p>","<ul><li>Vorgegebene <strong>Anzahl</strong> von Clustern</li><li><strong>Maximale Distanz</strong> im neuen Cluster über Schwellenwert</li><li><strong>Durchschnittliche maximale Distanz</strong> steigt stark an</li><li><strong>Cluster-Dichte</strong> unter Schwellenwert</li></ul>","week-2 ws-25-26 hierarchical-clustering stopping-criteria data-mining source::kapitel-2-folien"
"<p>Warum sollten Attribute vor dem Clustering standardisiert werden?</p>","<p>Damit unterschiedliche Skalen die Distanzberechnung nicht dominieren; Standardisierung auf <strong>Mittelwert 0</strong> und <strong>Standardabweichung 1</strong>.</p>","week-2 ws-25-26 preprocessing clustering data-mining source::kapitel-2-folien"
"<p>Was ist ein Clustroid in nicht-euklidischen Räumen?</p>","<ul><li>Punkt mit <strong>minimaler Summe</strong> aller Distanzen</li><li>oder Punkt mit <strong>minimaler maximaler Distanz</strong> zu den anderen Punkten</li></ul>","week-2 ws-25-26 clustering non-euclidean data-mining source::kapitel-2-folien"
"<p>Wie ist die Zeitkomplexität von hierarchischem Clustering?</p>","<ul><li><strong>Single Linkage:</strong> \(O(N^2)\)</li><li><strong>Andere Verfahren (Priority Queue):</strong> \(O(N^2 \log N)\)</li><li><strong>Naiv:</strong> bis \(O(N^3)\)</li></ul>","week-2 ws-25-26 complexity hierarchical-clustering data-mining source::kapitel-2-folien"
"<p>Was ist die Zielsetzung von k-Means-Clustering?</p>","<p>Eine Partition in <strong>k Cluster</strong> mit möglichst <strong>kleiner durchschnittlicher Distanz</strong> innerhalb der Cluster.</p>","week-2 ws-25-26 k-means clustering data-mining source::kapitel-2-folien"
"<p>Wie läuft der k-Means-Algorithmus ab?</p>","<ol><li><strong>k Centroiden</strong> initialisieren</li><li>Punkte dem <strong>nächstgelegenen Centroid</strong> zuordnen</li><li><strong>Centroiden</strong> neu berechnen</li><li>Wiederholen bis <strong>Konvergenz</strong></li></ol>","week-2 ws-25-26 k-means algorithm data-mining source::kapitel-2-folien"
"<p>Welche Initialisierungsstrategien für k-Means sind üblich?</p>","<ul><li>Zufällige Zuordnung der Punkte und Berechnung der Centroiden</li><li>Auswahl von <strong>k Punkten</strong> mit maximalen paarweisen Distanzen</li><li>Hierarchisches Clustering auf Stichprobe und Wahl der <strong>Clustroiden</strong></li></ul>","week-2 ws-25-26 k-means initialization data-mining source::kapitel-2-folien"
"<p>Warum wird k-Means oft mit mehreren Initialisierungen ausgeführt?</p>","<p>k-Means kann in einem <strong>lokalen Minimum</strong> enden; daher mehrere Starts und Auswahl des <strong>besten Ergebnisses</strong>.</p>","week-2 ws-25-26 k-means optimization data-mining source::kapitel-2-folien"
"<p>Wie kann man die Anzahl der Cluster k heuristisch wählen?</p>","<p><strong>k verdoppeln</strong> (2, 4, 8, 16, …) und im relevanten Bereich per <strong>binärer Suche</strong> verfeinern.</p>","week-2 ws-25-26 k-means model-selection data-mining source::kapitel-2-folien"
"<p>Was ist der BFR-Algorithmus?</p>","<p>Eine k-Means-Variante für <strong>sehr große Datensätze</strong>, die nicht in den Hauptspeicher passen; Annahme <strong>multivariat normalverteilter</strong> Cluster mit <strong>unabhängigen Dimensionen</strong>.</p>","week-2 ws-25-26 bfr clustering data-mining source::kapitel-2-folien"
"<p>Wie werden Cluster im BFR-Algorithmus effizient repräsentiert?</p>","<p><strong>2d + 1</strong> Zahlen: <strong>n</strong>, \(\text{SUM}_1..\text{SUM}_d\) und \(\text{SUMSQ}_1..\text{SUMSQ}_d\).</p>","week-2 ws-25-26 bfr clustering statistics data-mining source::kapitel-2-folien"
"<p>Wie berechnet man Centroid und Varianz aus den BFR-Statistiken?</p>","<p>Centroid: \(\mu = \frac{\text{SUM}}{n}\)<br>Varianz: \(\sigma^2 = \frac{\text{SUMSQ}}{n} - \left(\frac{\text{SUM}}{n}\right)^2\)</p>","week-2 ws-25-26 bfr clustering statistics data-mining source::kapitel-2-folien"
"<p>Welche drei Mengen verwendet der BFR-Algorithmus?</p>","<ul><li><strong>DS</strong>: zugeordnete Punkte</li><li><strong>RS</strong>: noch nicht zugeordnete Punkte</li><li><strong>CS</strong>: zusammengefasste Mini-Cluster aus RS</li></ul>","week-2 ws-25-26 bfr clustering data-mining source::kapitel-2-folien"
"<p>Wie läuft der BFR-Algorithmus grob ab?</p>","<ol><li><strong>k Cluster</strong> initialisieren</li><li>Daten <strong>chunkweise</strong> laden</li><li>Punkte mit geringer Distanz zu DS zuordnen</li><li>Restpunkte clustern → <strong>CS</strong> bilden</li><li>CS ggf. mit DS mergen</li><li>Am Ende CS/RS den nächstliegenden DS-Clustern zuordnen</li></ol>","week-2 ws-25-26 bfr algorithm data-mining source::kapitel-2-folien"
"<p>Nach welchem Kriterium wird ein Punkt im BFR-Algorithmus einem Cluster zugeordnet?</p>","<p>Minimaler <strong>Mahalanobis-Abstand</strong> zum Centroid und unter einem <strong>Schwellenwert</strong>.</p>","week-2 ws-25-26 bfr clustering distance-metrics data-mining source::kapitel-2-folien"
"<p>Wie ist der Mahalanobis-Abstand im BFR-Kontext definiert und welche Schwellenwerte sind typisch?</p>","<p>\(M(x, c) = \sum_{i=1}^{d} \left(\frac{x_i - c_i}{\sigma_i}\right)^2\)</p><ul><li>Ca. <strong>68%</strong>: \(M &lt; d\)</li><li>Ca. <strong>95%</strong>: \(M &lt; 2d\)</li></ul>","week-2 ws-25-26 bfr mahalanobis distance-metrics data-mining source::kapitel-2-folien"
"<p>Welche Einschränkungen von BFR adressiert der CURE-Algorithmus?</p>","<p>BFR setzt <strong>normalverteilte Cluster</strong> mit <strong>unabhängigen Dimensionen</strong> voraus; CURE erlaubt <strong>Cluster beliebiger Form</strong>.</p>","week-2 ws-25-26 cure bfr clustering data-mining source::kapitel-2-folien"
"<p>Wie funktioniert der CURE-Algorithmus in Grundzügen?</p>","<ol><li>Zufallsstichprobe ziehen</li><li>Hierarchisch clustern (agglomerativ, ohne Centroid bevorzugt)</li><li>Repräsentative Punkte je Cluster wählen (weit auseinander)</li><li>Repräsentanten zum Centroid um Anteil verschieben (z. B. 20%)</li><li>Cluster mergen, wenn max. Repräsentanten-Distanz klein ist</li><li>Alle Punkte dem nächsten Repräsentanten zuordnen</li></ol>","week-2 ws-25-26 cure clustering algorithm data-mining source::kapitel-2-folien"
